{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f8ca24",
   "metadata": {},
   "source": [
    "# Understanding Hired Rides in NYC\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1VERPjEZcC1XSs4-02aM-DbkNr_yaJVbFjLJxaYQswqA/edit#)_\n",
    "\n",
    "_This scaffolding notebook may be used to help setup your final project. It's **totally optional** whether you make use of this or not._\n",
    "\n",
    "_If you do use this notebook, everything provided is optional as well - you may remove or add prose and code as you wish._\n",
    "\n",
    "_Anything in italics (prose) or comments (in code) is meant to provide you with guidance. **Remove the italic lines and provided comments** before submitting the project, if you choose to use this scaffolding. We don't need the guidance when grading._\n",
    "\n",
    "_**All code below should be consider \"pseudo-code\" - not functional by itself, and only a suggestion at the approach.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75fd94",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66dcde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all import statements needed for the project, for example:\n",
    "\n",
    "import os\n",
    "\n",
    "import bs4\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sqlalchemy as db\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f1242c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any constants you might need; some have been added for you, and \n",
    "# some you need to fill in\n",
    "\n",
    "TLC_URL = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "\n",
    "TAXI_ZONES_DIR = \"\"\n",
    "TAXI_ZONES_SHAPEFILE = f\"{TAXI_ZONES_DIR}/taxi_zones.shp\"\n",
    "WEATHER_CSV_DIR = \"\"\n",
    "\n",
    "CRS = 4326  # coordinate reference system\n",
    "\n",
    "# (lat, lon)\n",
    "NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "LGA_BOX_COORDS = ((40.763589, -73.891745), (40.778865, -73.854838))\n",
    "JFK_BOX_COORDS = ((40.639263, -73.795642), (40.651376, -73.766264))\n",
    "EWR_BOX_COORDS = ((40.686794, -74.194028), (40.699680, -74.165205))\n",
    "\n",
    "DATABASE_URL = \"sqlite:///project_1.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6601633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the QUERY_DIRECTORY exists\n",
    "try:\n",
    "    os.mkdir(QUERY_DIRECTORY)\n",
    "except Exception as e:\n",
    "    if e.errno == 17:\n",
    "        # the directory already exists\n",
    "        pass\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad10ea",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d53e24",
   "metadata": {},
   "source": [
    "### Load Taxi Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e29e2467-f250-402a-abd1-77b8ae4f0344",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install geopandas\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58708809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_taxi_zones(shapefile):\n",
    "    '''\n",
    "    This function reads the taxi_zones file and change the location into latitude and longitude format\n",
    "    '''\n",
    "    data = gpd.read_file(shapefile)\n",
    "    \n",
    "    # change coordinate system since we need to compare to (40.560445, -74.242330) and (40.908524, -73.717047)\n",
    "    data = data.to_crs(epsg=4326) \n",
    "\n",
    "    # calculating latitude and longitude using given geo data\n",
    "    data[\"latitude\"] = data.geometry.centroid.y\n",
    "    data[\"longitude\"] = data.geometry.centroid.x\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85db23da-59e7-4f9f-96b9-a5b1508cd876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11211\\AppData\\Local\\Temp\\ipykernel_6424\\3344000312.py:11: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  data[\"latitude\"] = data.geometry.centroid.y\n",
      "C:\\Users\\11211\\AppData\\Local\\Temp\\ipykernel_6424\\3344000312.py:12: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  data[\"longitude\"] = data.geometry.centroid.x\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>zone</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>borough</th>\n",
       "      <th>geometry</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.116357</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>POLYGON ((-74.18445 40.695, -74.18449 40.6951,...</td>\n",
       "      <td>40.691831</td>\n",
       "      <td>-74.174000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.433470</td>\n",
       "      <td>0.004866</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>MULTIPOLYGON (((-73.82338 40.63899, -73.82277 ...</td>\n",
       "      <td>40.616745</td>\n",
       "      <td>-73.831299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.084341</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>POLYGON ((-73.84793 40.87134, -73.84725 40.870...</td>\n",
       "      <td>40.864474</td>\n",
       "      <td>-73.847422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.043567</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((-73.97177 40.72582, -73.97179 40.725...</td>\n",
       "      <td>40.723752</td>\n",
       "      <td>-73.976968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.092146</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>POLYGON ((-74.17422 40.56257, -74.17349 40.562...</td>\n",
       "      <td>40.552659</td>\n",
       "      <td>-74.188484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>259</td>\n",
       "      <td>0.126750</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>Woodlawn/Wakefield</td>\n",
       "      <td>259</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>POLYGON ((-73.85107 40.91037, -73.85207 40.909...</td>\n",
       "      <td>40.897932</td>\n",
       "      <td>-73.852215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>260</td>\n",
       "      <td>0.133514</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>Woodside</td>\n",
       "      <td>260</td>\n",
       "      <td>Queens</td>\n",
       "      <td>POLYGON ((-73.90175 40.76078, -73.90147 40.759...</td>\n",
       "      <td>40.744235</td>\n",
       "      <td>-73.906306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>261</td>\n",
       "      <td>0.027120</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>World Trade Center</td>\n",
       "      <td>261</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((-74.01333 40.70503, -74.01327 40.704...</td>\n",
       "      <td>40.709139</td>\n",
       "      <td>-74.013023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>262</td>\n",
       "      <td>0.049064</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>Yorkville East</td>\n",
       "      <td>262</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>MULTIPOLYGON (((-73.94383 40.78286, -73.94376 ...</td>\n",
       "      <td>40.775932</td>\n",
       "      <td>-73.946510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>263</td>\n",
       "      <td>0.037017</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>Yorkville West</td>\n",
       "      <td>263</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((-73.95219 40.77302, -73.95269 40.772...</td>\n",
       "      <td>40.778766</td>\n",
       "      <td>-73.951010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     OBJECTID  Shape_Leng  Shape_Area                     zone  LocationID  \\\n",
       "0           1    0.116357    0.000782           Newark Airport           1   \n",
       "1           2    0.433470    0.004866              Jamaica Bay           2   \n",
       "2           3    0.084341    0.000314  Allerton/Pelham Gardens           3   \n",
       "3           4    0.043567    0.000112            Alphabet City           4   \n",
       "4           5    0.092146    0.000498            Arden Heights           5   \n",
       "..        ...         ...         ...                      ...         ...   \n",
       "258       259    0.126750    0.000395       Woodlawn/Wakefield         259   \n",
       "259       260    0.133514    0.000422                 Woodside         260   \n",
       "260       261    0.027120    0.000034       World Trade Center         261   \n",
       "261       262    0.049064    0.000122           Yorkville East         262   \n",
       "262       263    0.037017    0.000066           Yorkville West         263   \n",
       "\n",
       "           borough                                           geometry  \\\n",
       "0              EWR  POLYGON ((-74.18445 40.695, -74.18449 40.6951,...   \n",
       "1           Queens  MULTIPOLYGON (((-73.82338 40.63899, -73.82277 ...   \n",
       "2            Bronx  POLYGON ((-73.84793 40.87134, -73.84725 40.870...   \n",
       "3        Manhattan  POLYGON ((-73.97177 40.72582, -73.97179 40.725...   \n",
       "4    Staten Island  POLYGON ((-74.17422 40.56257, -74.17349 40.562...   \n",
       "..             ...                                                ...   \n",
       "258          Bronx  POLYGON ((-73.85107 40.91037, -73.85207 40.909...   \n",
       "259         Queens  POLYGON ((-73.90175 40.76078, -73.90147 40.759...   \n",
       "260      Manhattan  POLYGON ((-74.01333 40.70503, -74.01327 40.704...   \n",
       "261      Manhattan  MULTIPOLYGON (((-73.94383 40.78286, -73.94376 ...   \n",
       "262      Manhattan  POLYGON ((-73.95219 40.77302, -73.95269 40.772...   \n",
       "\n",
       "      latitude  longitude  \n",
       "0    40.691831 -74.174000  \n",
       "1    40.616745 -73.831299  \n",
       "2    40.864474 -73.847422  \n",
       "3    40.723752 -73.976968  \n",
       "4    40.552659 -74.188484  \n",
       "..         ...        ...  \n",
       "258  40.897932 -73.852215  \n",
       "259  40.744235 -73.906306  \n",
       "260  40.709139 -74.013023  \n",
       "261  40.775932 -73.946510  \n",
       "262  40.778766 -73.951010  \n",
       "\n",
       "[263 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_zones = load_taxi_zones(\"taxi_zones.shp\")\n",
    "taxi_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d04c726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_coords_for_taxi_zone_id(zone_loc_id, loaded_taxi_zones):\n",
    "    '''\n",
    "    This function load takes id and the loaded taxi zone df and return the id's corresponding lat,lon pair\n",
    "    '''\n",
    "    zone = loaded_taxi_zones[loaded_taxi_zones[\"LocationID\"] == zone_loc_id]\n",
    "    if zone.empty:\n",
    "        return 0.0,0.0\n",
    "        \n",
    "    lat = zone[\"latitude\"].values[0]\n",
    "    lon= zone[\"longitude\"].values[0]\n",
    "    return lat,lon\n",
    "\n",
    "def get_coords(id):\n",
    "    return lookup_coords_for_taxi_zone_id(id, taxi_zones)\n",
    "    \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32074561",
   "metadata": {},
   "source": [
    "### Calculate Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cbbe6cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def calculate_sample_size(population):\n",
    "    '''\n",
    "    According to the Youtube video\n",
    "    https://www.youtube.com/watch?v=dRYKi6pIUaU\n",
    "    Our sample size should be n1 = 385/(1+ 384/N) where N is our poplulation size\n",
    "    385 is a constant calculated by the video\n",
    "    '''\n",
    "    return math.ceil(385/(1+384/population))\n",
    "\n",
    "'''\n",
    "test \n",
    "'''\n",
    "calculate_sample_size(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc33eed4-b2e9-4ab3-94a8-59f04e464c98",
   "metadata": {},
   "source": [
    "### Common Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a0fdc7-fd3d-4d6c-8ce9-f7c90f0b846f",
   "metadata": {},
   "source": [
    "The cells below takes the TLC_URL linke to obtain a list of all yellow cab and fhvhv data parquet links.\n",
    "\n",
    "### get_all_urls_from_tlc_page(taxi_page)\n",
    "\n",
    "Str_of_URL -> Str_of_html_content\n",
    "\n",
    "get_all_urls_from_tlc_page takes the TLC_URL link and return its html content for filter_parquet_urls to continue\n",
    "\n",
    "\n",
    "\n",
    "### filter_parquet_urls(all_urls)\n",
    "\n",
    "Str_of_html_content -> List_of_parquet_links\n",
    "\n",
    "filter_parquet_urls takes the html content returned by previous function and return a list of all yellow cabs and fhvhv cars' link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1dd682b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_urls_from_tlc_page(taxi_page):\n",
    "    response = requests.get(taxi_page)\n",
    "    html = response.content\n",
    "    return html\n",
    "\n",
    "all_urls = get_all_urls_from_tlc_page(TLC_URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbd0d198",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def filter_parquet_urls(all_urls):\n",
    "    soup = bs4.BeautifulSoup(all_urls, \"html.parser\")\n",
    "    yellow_a_tags = soup.find_all(\"a\", attrs={\"title\": \"Yellow Taxi Trip Records\"})\n",
    "    HVFHV_a_tags = soup.find_all(\"a\", attrs={\"title\": \"High Volume For-Hire Vehicle Trip Records\"})\n",
    "    all_a_tags = yellow_a_tags + HVFHV_a_tags\n",
    "    return [a[\"href\"] for a in all_a_tags]\n",
    "\n",
    "all_parquet_urls = filter_parquet_urls(all_urls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06978281-7fda-480e-b099-a37ef2356994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d428f191-4a15-4f0f-9541-3bacdc75186b",
   "metadata": {},
   "source": [
    "### select_parquet(all_urls)\n",
    "\n",
    "List_of_parquet -> List_of_parquet\n",
    "\n",
    "select_parquet(all_urls) takes a list of parquets and filter out all parquets not in the Jan 2020 - Aug 2024 period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb2d9271-33b0-4970-8d42-d33e3ba842f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_parquet(all_urls):\n",
    "    result =[]\n",
    "    for i in range(len(all_urls)):\n",
    "        curr_url = all_urls[i]\n",
    "        pattern = r\"(\\d{4})-(\\d{2})\"\n",
    "        match = re.search(pattern, curr_url)\n",
    "        year_str = int(match.group(1))\n",
    "        month_str = int(match.group(2))\n",
    "        if (year_str < 2020):\n",
    "            continue\n",
    "        if (year_str >= 2024 and month_str > 8):\n",
    "            continue\n",
    "        result += [curr_url]       \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "849ec50f-bf7d-4d43-8bec-bbfca65d7877",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_parquests = select_parquet(all_parquet_urls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98146c6-30f2-4fc7-8c9a-688ea6a0b489",
   "metadata": {},
   "source": [
    "### select_yellow(urls)\n",
    "\n",
    "List_of_parquet -> List_of_parquet\n",
    "\n",
    "select_yellow(urls) takes the parquet filterd by select_parquet and returns all the yellow cabs link as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe6df7e9-4404-44fc-af27-da8f920dc722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_yellow(urls):\n",
    "    result =[]\n",
    "    for i in range(len(urls)):\n",
    "        curr_url = urls[i]\n",
    "        if not isinstance(curr_url, str):\n",
    "            continue\n",
    "        pattern = r\"yellow\"\n",
    "        match = re.search(pattern, curr_url)\n",
    "        if match is None:\n",
    "            continue\n",
    "        else: \n",
    "            result += [curr_url]       \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91d29328-0fe9-4864-a314-62eafe9b6bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_parquests\n",
    "yellow_cabs = select_yellow(required_parquests)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a01139-18e3-402e-b553-0d629d2f0855",
   "metadata": {},
   "source": [
    "### select_fhvhv(urls)\n",
    "\n",
    "List_of_parquet -> List_of_parquet\n",
    "\n",
    "Same as select_yellow, but it returns fhvhv links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7694dcac-eeef-4f38-bca9-dc695160bb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_fhvhv(urls):\n",
    "    result =[]\n",
    "    for i in range(len(urls)):\n",
    "        curr_url = urls[i]\n",
    "        if not isinstance(curr_url, str):\n",
    "            continue\n",
    "        pattern = r\"fhvhv\"\n",
    "        match = re.search(pattern, curr_url)\n",
    "        if match is None:\n",
    "            continue\n",
    "        else: \n",
    "            result += [curr_url]       \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "356a033d-0412-4e3f-bc30-3e3c6fdc8623",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "required_parquests\n",
    "fhvhv_cabs = select_fhvhv(required_parquests)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e724af-3f3b-4933-a680-a6af09f16f41",
   "metadata": {},
   "source": [
    "### download_one(url, save_name)\n",
    "\n",
    "Str_of_parquet ->None\n",
    "\n",
    "Output: 1.message of download result\n",
    "        2.download a file\n",
    "\n",
    "download_one(url, save_name) takes a parquet link of yellow cab or fhvhv, then write the data into a local file named save_name. It prints a message if download is successful and raise a http error otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8af1defd-6584-4514-9117-99bb2e664da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_one(url, save_name):\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()  \n",
    "\n",
    "    with open(save_name, 'wb') as file:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            if chunk:\n",
    "                file.write(chunk)\n",
    "\n",
    "    print(f\"File downloaded successfully as {save_name}\")\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f902b1d-3af4-40de-a32c-32556853a4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully as fhvhv_tripdata_2024-01.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hvfhs_license_num</th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>originating_base_num</th>\n",
       "      <th>request_datetime</th>\n",
       "      <th>on_scene_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>...</th>\n",
       "      <th>sales_tax</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>tips</th>\n",
       "      <th>driver_pay</th>\n",
       "      <th>shared_request_flag</th>\n",
       "      <th>shared_match_flag</th>\n",
       "      <th>access_a_ride_flag</th>\n",
       "      <th>wav_request_flag</th>\n",
       "      <th>wav_match_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2024-01-01 00:21:47</td>\n",
       "      <td>2024-01-01 00:25:06</td>\n",
       "      <td>2024-01-01 00:28:08</td>\n",
       "      <td>2024-01-01 01:05:39</td>\n",
       "      <td>161</td>\n",
       "      <td>158</td>\n",
       "      <td>2.83</td>\n",
       "      <td>...</td>\n",
       "      <td>4.05</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.18</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2024-01-01 00:10:56</td>\n",
       "      <td>2024-01-01 00:11:08</td>\n",
       "      <td>2024-01-01 00:12:53</td>\n",
       "      <td>2024-01-01 00:20:05</td>\n",
       "      <td>137</td>\n",
       "      <td>79</td>\n",
       "      <td>1.57</td>\n",
       "      <td>...</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.12</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2024-01-01 00:20:04</td>\n",
       "      <td>2024-01-01 00:21:51</td>\n",
       "      <td>2024-01-01 00:23:05</td>\n",
       "      <td>2024-01-01 00:35:16</td>\n",
       "      <td>79</td>\n",
       "      <td>186</td>\n",
       "      <td>1.98</td>\n",
       "      <td>...</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.47</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2024-01-01 00:35:46</td>\n",
       "      <td>2024-01-01 00:39:59</td>\n",
       "      <td>2024-01-01 00:41:04</td>\n",
       "      <td>2024-01-01 00:56:34</td>\n",
       "      <td>234</td>\n",
       "      <td>148</td>\n",
       "      <td>1.99</td>\n",
       "      <td>...</td>\n",
       "      <td>1.52</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.35</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2024-01-01 00:48:19</td>\n",
       "      <td>2024-01-01 00:56:23</td>\n",
       "      <td>2024-01-01 00:57:21</td>\n",
       "      <td>2024-01-01 01:10:02</td>\n",
       "      <td>148</td>\n",
       "      <td>97</td>\n",
       "      <td>2.65</td>\n",
       "      <td>...</td>\n",
       "      <td>3.43</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.63</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19663925</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2024-01-31 23:24:46</td>\n",
       "      <td>2024-01-31 23:26:11</td>\n",
       "      <td>2024-01-31 23:28:08</td>\n",
       "      <td>2024-01-31 23:32:13</td>\n",
       "      <td>79</td>\n",
       "      <td>113</td>\n",
       "      <td>0.65</td>\n",
       "      <td>...</td>\n",
       "      <td>0.81</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.39</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19663926</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2024-01-31 23:33:02</td>\n",
       "      <td>2024-01-31 23:34:07</td>\n",
       "      <td>2024-01-31 23:34:19</td>\n",
       "      <td>2024-02-01 00:07:53</td>\n",
       "      <td>113</td>\n",
       "      <td>248</td>\n",
       "      <td>13.32</td>\n",
       "      <td>...</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>36.43</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19663927</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2024-01-31 23:28:59</td>\n",
       "      <td>2024-01-31 23:30:51</td>\n",
       "      <td>2024-01-31 23:31:14</td>\n",
       "      <td>2024-01-31 23:38:18</td>\n",
       "      <td>161</td>\n",
       "      <td>50</td>\n",
       "      <td>1.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.71</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19663928</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2024-01-31 23:39:00</td>\n",
       "      <td>2024-01-31 23:41:03</td>\n",
       "      <td>2024-01-31 23:41:45</td>\n",
       "      <td>2024-01-31 23:52:40</td>\n",
       "      <td>246</td>\n",
       "      <td>163</td>\n",
       "      <td>1.57</td>\n",
       "      <td>...</td>\n",
       "      <td>1.62</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.62</td>\n",
       "      <td>8.54</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19663929</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2024-01-31 23:54:54</td>\n",
       "      <td>2024-01-31 23:57:59</td>\n",
       "      <td>2024-01-31 23:58:25</td>\n",
       "      <td>2024-02-01 00:02:10</td>\n",
       "      <td>161</td>\n",
       "      <td>162</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>0.73</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.40</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19663930 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         hvfhs_license_num dispatching_base_num originating_base_num  \\\n",
       "0                   HV0003               B03404               B03404   \n",
       "1                   HV0003               B03404               B03404   \n",
       "2                   HV0003               B03404               B03404   \n",
       "3                   HV0003               B03404               B03404   \n",
       "4                   HV0003               B03404               B03404   \n",
       "...                    ...                  ...                  ...   \n",
       "19663925            HV0003               B03404               B03404   \n",
       "19663926            HV0003               B03404               B03404   \n",
       "19663927            HV0003               B03404               B03404   \n",
       "19663928            HV0003               B03404               B03404   \n",
       "19663929            HV0003               B03404               B03404   \n",
       "\n",
       "            request_datetime   on_scene_datetime     pickup_datetime  \\\n",
       "0        2024-01-01 00:21:47 2024-01-01 00:25:06 2024-01-01 00:28:08   \n",
       "1        2024-01-01 00:10:56 2024-01-01 00:11:08 2024-01-01 00:12:53   \n",
       "2        2024-01-01 00:20:04 2024-01-01 00:21:51 2024-01-01 00:23:05   \n",
       "3        2024-01-01 00:35:46 2024-01-01 00:39:59 2024-01-01 00:41:04   \n",
       "4        2024-01-01 00:48:19 2024-01-01 00:56:23 2024-01-01 00:57:21   \n",
       "...                      ...                 ...                 ...   \n",
       "19663925 2024-01-31 23:24:46 2024-01-31 23:26:11 2024-01-31 23:28:08   \n",
       "19663926 2024-01-31 23:33:02 2024-01-31 23:34:07 2024-01-31 23:34:19   \n",
       "19663927 2024-01-31 23:28:59 2024-01-31 23:30:51 2024-01-31 23:31:14   \n",
       "19663928 2024-01-31 23:39:00 2024-01-31 23:41:03 2024-01-31 23:41:45   \n",
       "19663929 2024-01-31 23:54:54 2024-01-31 23:57:59 2024-01-31 23:58:25   \n",
       "\n",
       "            dropoff_datetime  PULocationID  DOLocationID  trip_miles  ...  \\\n",
       "0        2024-01-01 01:05:39           161           158        2.83  ...   \n",
       "1        2024-01-01 00:20:05           137            79        1.57  ...   \n",
       "2        2024-01-01 00:35:16            79           186        1.98  ...   \n",
       "3        2024-01-01 00:56:34           234           148        1.99  ...   \n",
       "4        2024-01-01 01:10:02           148            97        2.65  ...   \n",
       "...                      ...           ...           ...         ...  ...   \n",
       "19663925 2024-01-31 23:32:13            79           113        0.65  ...   \n",
       "19663926 2024-02-01 00:07:53           113           248       13.32  ...   \n",
       "19663927 2024-01-31 23:38:18           161            50        1.31  ...   \n",
       "19663928 2024-01-31 23:52:40           246           163        1.57  ...   \n",
       "19663929 2024-02-01 00:02:10           161           162        0.39  ...   \n",
       "\n",
       "          sales_tax  congestion_surcharge  airport_fee  tips  driver_pay  \\\n",
       "0              4.05                  2.75          0.0  0.00       40.18   \n",
       "1              0.89                  2.75          0.0  0.00        6.12   \n",
       "2              1.60                  2.75          0.0  0.00        9.47   \n",
       "3              1.52                  2.75          0.0  0.00       11.35   \n",
       "4              3.43                  2.75          0.0  0.00       28.63   \n",
       "...             ...                   ...          ...   ...         ...   \n",
       "19663925       0.81                  2.75          0.0  1.00        5.39   \n",
       "19663926       3.19                  2.75          0.0  0.00       36.43   \n",
       "19663927       0.89                  2.75          0.0  0.00        5.71   \n",
       "19663928       1.62                  2.75          0.0  4.62        8.54   \n",
       "19663929       0.73                  2.75          0.0  0.00        5.40   \n",
       "\n",
       "          shared_request_flag  shared_match_flag  access_a_ride_flag  \\\n",
       "0                           N                  N                   N   \n",
       "1                           N                  N                   N   \n",
       "2                           N                  N                   N   \n",
       "3                           N                  N                   N   \n",
       "4                           N                  N                   N   \n",
       "...                       ...                ...                 ...   \n",
       "19663925                    N                  N                   N   \n",
       "19663926                    N                  N                   N   \n",
       "19663927                    N                  N                   N   \n",
       "19663928                    N                  N                   N   \n",
       "19663929                    N                  N                   N   \n",
       "\n",
       "          wav_request_flag wav_match_flag  \n",
       "0                        N              N  \n",
       "1                        N              N  \n",
       "2                        N              N  \n",
       "3                        N              N  \n",
       "4                        N              N  \n",
       "...                    ...            ...  \n",
       "19663925                 N              N  \n",
       "19663926                 N              N  \n",
       "19663927                 N              N  \n",
       "19663928                 N              N  \n",
       "19663929                 N              N  \n",
       "\n",
       "[19663930 rows x 24 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_one('https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-01.parquet','fhvhv_tripdata_2024-01.parquet')\n",
    "df = pd.read_parquet('fhvhv_tripdata_2024-01.parquet')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91f6ed8-307f-4730-9a13-e19b1c88f5f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f081924-59b5-4a2e-bc9a-6b5c207cd318",
   "metadata": {},
   "source": [
    "### data download\n",
    "\n",
    "The cells below using for loops to call download_one repeatedly to download all yellow cabs and fhvhv parquet data. It uses url.strip() because sometimes we might have a white space in the end of input parquet link which might cause 403 error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8fffdeea-a733-4a84-8a58-50ef3bc759c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully as fhvhv_tripdata_2024-01.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2024-02.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2024-03.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2024-04.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2024-05.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2024-06.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2024-07.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2024-08.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2023-01.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2023-02.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2023-03.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2023-04.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2023-05.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2023-06.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2023-07.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2023-08.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2023-09.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2023-10.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2023-11.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2023-12.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2022-01.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2022-02.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2022-03.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2022-04.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2022-05.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2022-06.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2022-07.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2022-08.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2022-09.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2022-10.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2022-11.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2022-12.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2021-01.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2021-02.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2021-03.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2021-04.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2021-05.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2021-06.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2021-07.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2021-08.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2021-09.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2021-10.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2021-11.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2021-12.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2020-01.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2020-02.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2020-03.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2020-04.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2020-05.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2020-06.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2020-07.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2020-08.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2020-09.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2020-10.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2020-11.parquet\n",
      "File downloaded successfully as fhvhv_tripdata_2020-12.parquet\n"
     ]
    }
   ],
   "source": [
    "uber_urls = [] #create list of urls for cleanning all the datasets\n",
    "for i in fhvhv_cabs:\n",
    "    url = i\n",
    "    url = url.strip()\n",
    "    pattern = r\"fhvhv_tripdata_\\d{4}-\\d{2}\\.parquet\"\n",
    "    match = re.search(pattern, url)\n",
    "    save_name = match.group()\n",
    "    download_one(url, save_name)\n",
    "    uber_urls.append(save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b9e4994-6c53-4c3d-9587-409dac1ab2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully as yellow_tripdata_2024-01.parquet\n",
      "File downloaded successfully as yellow_tripdata_2024-02.parquet\n",
      "File downloaded successfully as yellow_tripdata_2024-03.parquet\n",
      "File downloaded successfully as yellow_tripdata_2024-04.parquet\n",
      "File downloaded successfully as yellow_tripdata_2024-05.parquet\n",
      "File downloaded successfully as yellow_tripdata_2024-06.parquet\n",
      "File downloaded successfully as yellow_tripdata_2024-07.parquet\n",
      "File downloaded successfully as yellow_tripdata_2024-08.parquet\n",
      "File downloaded successfully as yellow_tripdata_2023-01.parquet\n",
      "File downloaded successfully as yellow_tripdata_2023-02.parquet\n",
      "File downloaded successfully as yellow_tripdata_2023-03.parquet\n",
      "File downloaded successfully as yellow_tripdata_2023-04.parquet\n",
      "File downloaded successfully as yellow_tripdata_2023-05.parquet\n",
      "File downloaded successfully as yellow_tripdata_2023-06.parquet\n",
      "File downloaded successfully as yellow_tripdata_2023-07.parquet\n",
      "File downloaded successfully as yellow_tripdata_2023-08.parquet\n",
      "File downloaded successfully as yellow_tripdata_2023-09.parquet\n",
      "File downloaded successfully as yellow_tripdata_2023-10.parquet\n",
      "File downloaded successfully as yellow_tripdata_2023-11.parquet\n",
      "File downloaded successfully as yellow_tripdata_2023-12.parquet\n",
      "File downloaded successfully as yellow_tripdata_2022-01.parquet\n",
      "File downloaded successfully as yellow_tripdata_2022-02.parquet\n",
      "File downloaded successfully as yellow_tripdata_2022-03.parquet\n",
      "File downloaded successfully as yellow_tripdata_2022-04.parquet\n",
      "File downloaded successfully as yellow_tripdata_2022-05.parquet\n",
      "File downloaded successfully as yellow_tripdata_2022-06.parquet\n",
      "File downloaded successfully as yellow_tripdata_2022-07.parquet\n",
      "File downloaded successfully as yellow_tripdata_2022-08.parquet\n",
      "File downloaded successfully as yellow_tripdata_2022-09.parquet\n",
      "File downloaded successfully as yellow_tripdata_2022-10.parquet\n",
      "File downloaded successfully as yellow_tripdata_2022-11.parquet\n",
      "File downloaded successfully as yellow_tripdata_2022-12.parquet\n",
      "File downloaded successfully as yellow_tripdata_2021-01.parquet\n",
      "File downloaded successfully as yellow_tripdata_2021-02.parquet\n",
      "File downloaded successfully as yellow_tripdata_2021-03.parquet\n",
      "File downloaded successfully as yellow_tripdata_2021-04.parquet\n",
      "File downloaded successfully as yellow_tripdata_2021-05.parquet\n",
      "File downloaded successfully as yellow_tripdata_2021-06.parquet\n",
      "File downloaded successfully as yellow_tripdata_2021-07.parquet\n",
      "File downloaded successfully as yellow_tripdata_2021-08.parquet\n",
      "File downloaded successfully as yellow_tripdata_2021-09.parquet\n",
      "File downloaded successfully as yellow_tripdata_2021-10.parquet\n",
      "File downloaded successfully as yellow_tripdata_2021-11.parquet\n",
      "File downloaded successfully as yellow_tripdata_2021-12.parquet\n",
      "File downloaded successfully as yellow_tripdata_2020-01.parquet\n",
      "File downloaded successfully as yellow_tripdata_2020-02.parquet\n",
      "File downloaded successfully as yellow_tripdata_2020-03.parquet\n",
      "File downloaded successfully as yellow_tripdata_2020-04.parquet\n",
      "File downloaded successfully as yellow_tripdata_2020-05.parquet\n",
      "File downloaded successfully as yellow_tripdata_2020-06.parquet\n",
      "File downloaded successfully as yellow_tripdata_2020-07.parquet\n",
      "File downloaded successfully as yellow_tripdata_2020-08.parquet\n",
      "File downloaded successfully as yellow_tripdata_2020-09.parquet\n",
      "File downloaded successfully as yellow_tripdata_2020-10.parquet\n",
      "File downloaded successfully as yellow_tripdata_2020-11.parquet\n",
      "File downloaded successfully as yellow_tripdata_2020-12.parquet\n"
     ]
    }
   ],
   "source": [
    "taxi_urls = [] #create list of urls for cleanning all the datasets\n",
    "for i in yellow_cabs:\n",
    "    url = i\n",
    "    url = url.strip()\n",
    "    pattern = r\"yellow_tripdata_\\d{4}-\\d{2}\\.parquet\"\n",
    "    match = re.search(pattern, url)\n",
    "    save_name = match.group()\n",
    "    download_one(url, save_name)\n",
    "    taxi_urls.append(save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a120f107-ee76-42fa-b54b-6991e7da36ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yellow_tripdata_2024-01.parquet',\n",
       " 'yellow_tripdata_2024-02.parquet',\n",
       " 'yellow_tripdata_2024-03.parquet',\n",
       " 'yellow_tripdata_2024-04.parquet',\n",
       " 'yellow_tripdata_2024-05.parquet',\n",
       " 'yellow_tripdata_2024-06.parquet',\n",
       " 'yellow_tripdata_2024-07.parquet',\n",
       " 'yellow_tripdata_2024-08.parquet',\n",
       " 'yellow_tripdata_2023-01.parquet',\n",
       " 'yellow_tripdata_2023-02.parquet',\n",
       " 'yellow_tripdata_2023-03.parquet',\n",
       " 'yellow_tripdata_2023-04.parquet',\n",
       " 'yellow_tripdata_2023-05.parquet',\n",
       " 'yellow_tripdata_2023-06.parquet',\n",
       " 'yellow_tripdata_2023-07.parquet',\n",
       " 'yellow_tripdata_2023-08.parquet',\n",
       " 'yellow_tripdata_2023-09.parquet',\n",
       " 'yellow_tripdata_2023-10.parquet',\n",
       " 'yellow_tripdata_2023-11.parquet',\n",
       " 'yellow_tripdata_2023-12.parquet',\n",
       " 'yellow_tripdata_2022-01.parquet',\n",
       " 'yellow_tripdata_2022-02.parquet',\n",
       " 'yellow_tripdata_2022-03.parquet',\n",
       " 'yellow_tripdata_2022-04.parquet',\n",
       " 'yellow_tripdata_2022-05.parquet',\n",
       " 'yellow_tripdata_2022-06.parquet',\n",
       " 'yellow_tripdata_2022-07.parquet',\n",
       " 'yellow_tripdata_2022-08.parquet',\n",
       " 'yellow_tripdata_2022-09.parquet',\n",
       " 'yellow_tripdata_2022-10.parquet',\n",
       " 'yellow_tripdata_2022-11.parquet',\n",
       " 'yellow_tripdata_2022-12.parquet',\n",
       " 'yellow_tripdata_2021-01.parquet',\n",
       " 'yellow_tripdata_2021-02.parquet',\n",
       " 'yellow_tripdata_2021-03.parquet',\n",
       " 'yellow_tripdata_2021-04.parquet',\n",
       " 'yellow_tripdata_2021-05.parquet',\n",
       " 'yellow_tripdata_2021-06.parquet',\n",
       " 'yellow_tripdata_2021-07.parquet',\n",
       " 'yellow_tripdata_2021-08.parquet',\n",
       " 'yellow_tripdata_2021-09.parquet',\n",
       " 'yellow_tripdata_2021-10.parquet',\n",
       " 'yellow_tripdata_2021-11.parquet',\n",
       " 'yellow_tripdata_2021-12.parquet',\n",
       " 'yellow_tripdata_2020-01.parquet',\n",
       " 'yellow_tripdata_2020-02.parquet',\n",
       " 'yellow_tripdata_2020-03.parquet',\n",
       " 'yellow_tripdata_2020-04.parquet',\n",
       " 'yellow_tripdata_2020-05.parquet',\n",
       " 'yellow_tripdata_2020-06.parquet',\n",
       " 'yellow_tripdata_2020-07.parquet',\n",
       " 'yellow_tripdata_2020-08.parquet',\n",
       " 'yellow_tripdata_2020-09.parquet',\n",
       " 'yellow_tripdata_2020-10.parquet',\n",
       " 'yellow_tripdata_2020-11.parquet',\n",
       " 'yellow_tripdata_2020-12.parquet']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87288ed7-ccd8-475c-a364-62917972ddb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yellow_tripdata_2024-01.parquet',\n",
       " 'yellow_tripdata_2024-02.parquet',\n",
       " 'yellow_tripdata_2024-03.parquet',\n",
       " 'yellow_tripdata_2024-04.parquet',\n",
       " 'yellow_tripdata_2024-05.parquet',\n",
       " 'yellow_tripdata_2024-06.parquet',\n",
       " 'yellow_tripdata_2024-07.parquet',\n",
       " 'yellow_tripdata_2024-08.parquet',\n",
       " 'yellow_tripdata_2023-01.parquet',\n",
       " 'yellow_tripdata_2023-02.parquet',\n",
       " 'yellow_tripdata_2023-03.parquet',\n",
       " 'yellow_tripdata_2023-04.parquet',\n",
       " 'yellow_tripdata_2023-05.parquet',\n",
       " 'yellow_tripdata_2023-06.parquet',\n",
       " 'yellow_tripdata_2023-07.parquet',\n",
       " 'yellow_tripdata_2023-08.parquet',\n",
       " 'yellow_tripdata_2023-09.parquet',\n",
       " 'yellow_tripdata_2023-10.parquet',\n",
       " 'yellow_tripdata_2023-11.parquet',\n",
       " 'yellow_tripdata_2023-12.parquet',\n",
       " 'yellow_tripdata_2022-01.parquet',\n",
       " 'yellow_tripdata_2022-02.parquet',\n",
       " 'yellow_tripdata_2022-03.parquet',\n",
       " 'yellow_tripdata_2022-04.parquet',\n",
       " 'yellow_tripdata_2022-05.parquet',\n",
       " 'yellow_tripdata_2022-06.parquet',\n",
       " 'yellow_tripdata_2022-07.parquet',\n",
       " 'yellow_tripdata_2022-08.parquet',\n",
       " 'yellow_tripdata_2022-09.parquet',\n",
       " 'yellow_tripdata_2022-10.parquet',\n",
       " 'yellow_tripdata_2022-11.parquet',\n",
       " 'yellow_tripdata_2022-12.parquet',\n",
       " 'yellow_tripdata_2021-01.parquet',\n",
       " 'yellow_tripdata_2021-02.parquet',\n",
       " 'yellow_tripdata_2021-03.parquet',\n",
       " 'yellow_tripdata_2021-04.parquet',\n",
       " 'yellow_tripdata_2021-05.parquet',\n",
       " 'yellow_tripdata_2021-06.parquet',\n",
       " 'yellow_tripdata_2021-07.parquet',\n",
       " 'yellow_tripdata_2021-08.parquet',\n",
       " 'yellow_tripdata_2021-09.parquet',\n",
       " 'yellow_tripdata_2021-10.parquet',\n",
       " 'yellow_tripdata_2021-11.parquet',\n",
       " 'yellow_tripdata_2021-12.parquet',\n",
       " 'yellow_tripdata_2020-01.parquet',\n",
       " 'yellow_tripdata_2020-02.parquet',\n",
       " 'yellow_tripdata_2020-03.parquet',\n",
       " 'yellow_tripdata_2020-04.parquet',\n",
       " 'yellow_tripdata_2020-05.parquet',\n",
       " 'yellow_tripdata_2020-06.parquet',\n",
       " 'yellow_tripdata_2020-07.parquet',\n",
       " 'yellow_tripdata_2020-08.parquet',\n",
       " 'yellow_tripdata_2020-09.parquet',\n",
       " 'yellow_tripdata_2020-10.parquet',\n",
       " 'yellow_tripdata_2020-11.parquet',\n",
       " 'yellow_tripdata_2020-12.parquet']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93daa717",
   "metadata": {},
   "source": [
    "### Process Taxi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f40130a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "population is 3399549 and calculated sample size is 385\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_time</th>\n",
       "      <th>dropoff_time</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pick_up_location</th>\n",
       "      <th>drop_off_location</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>pick_up_lat</th>\n",
       "      <th>pick_up_lon</th>\n",
       "      <th>drop_off_lat</th>\n",
       "      <th>drop_off_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2081085</th>\n",
       "      <td>2022-12-18 14:00:25</td>\n",
       "      <td>2022-12-18 14:24:30</td>\n",
       "      <td>4.20</td>\n",
       "      <td>41</td>\n",
       "      <td>48</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>21.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.804334</td>\n",
       "      <td>-73.951292</td>\n",
       "      <td>40.762253</td>\n",
       "      <td>-73.989845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182531</th>\n",
       "      <td>2022-12-10 19:00:09</td>\n",
       "      <td>2022-12-10 19:17:08</td>\n",
       "      <td>1.35</td>\n",
       "      <td>148</td>\n",
       "      <td>107</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17.76</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.718938</td>\n",
       "      <td>-73.990896</td>\n",
       "      <td>40.736824</td>\n",
       "      <td>-73.984052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474122</th>\n",
       "      <td>2022-12-04 21:05:39</td>\n",
       "      <td>2022-12-04 21:14:34</td>\n",
       "      <td>1.77</td>\n",
       "      <td>113</td>\n",
       "      <td>170</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.16</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.732579</td>\n",
       "      <td>-73.994305</td>\n",
       "      <td>40.747746</td>\n",
       "      <td>-73.978492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325629</th>\n",
       "      <td>2022-12-12 08:39:43</td>\n",
       "      <td>2022-12-12 08:48:15</td>\n",
       "      <td>1.54</td>\n",
       "      <td>237</td>\n",
       "      <td>161</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.04</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.768615</td>\n",
       "      <td>-73.965635</td>\n",
       "      <td>40.758028</td>\n",
       "      <td>-73.977698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3148362</th>\n",
       "      <td>2022-12-30 15:52:59</td>\n",
       "      <td>2022-12-30 16:06:11</td>\n",
       "      <td>1.54</td>\n",
       "      <td>237</td>\n",
       "      <td>162</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.50</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.768615</td>\n",
       "      <td>-73.965635</td>\n",
       "      <td>40.756688</td>\n",
       "      <td>-73.972356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3081215</th>\n",
       "      <td>2022-12-29 19:11:03</td>\n",
       "      <td>2022-12-29 19:24:27</td>\n",
       "      <td>1.10</td>\n",
       "      <td>186</td>\n",
       "      <td>246</td>\n",
       "      <td>11.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.50</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.748497</td>\n",
       "      <td>-73.992438</td>\n",
       "      <td>40.753309</td>\n",
       "      <td>-74.004015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66867</th>\n",
       "      <td>2022-12-01 16:53:11</td>\n",
       "      <td>2022-12-01 16:58:08</td>\n",
       "      <td>0.96</td>\n",
       "      <td>238</td>\n",
       "      <td>236</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.791705</td>\n",
       "      <td>-73.973049</td>\n",
       "      <td>40.780436</td>\n",
       "      <td>-73.957012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065815</th>\n",
       "      <td>2022-12-09 20:47:18</td>\n",
       "      <td>2022-12-09 20:53:25</td>\n",
       "      <td>1.29</td>\n",
       "      <td>237</td>\n",
       "      <td>262</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.36</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.768615</td>\n",
       "      <td>-73.965635</td>\n",
       "      <td>40.775932</td>\n",
       "      <td>-73.946510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2371465</th>\n",
       "      <td>2022-12-21 10:12:25</td>\n",
       "      <td>2022-12-21 10:25:47</td>\n",
       "      <td>1.80</td>\n",
       "      <td>236</td>\n",
       "      <td>237</td>\n",
       "      <td>12.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.80</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.780436</td>\n",
       "      <td>-73.957012</td>\n",
       "      <td>40.768615</td>\n",
       "      <td>-73.965635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685084</th>\n",
       "      <td>2022-12-06 20:04:11</td>\n",
       "      <td>2022-12-06 20:13:23</td>\n",
       "      <td>0.97</td>\n",
       "      <td>170</td>\n",
       "      <td>229</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.56</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.747746</td>\n",
       "      <td>-73.978492</td>\n",
       "      <td>40.756729</td>\n",
       "      <td>-73.965146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>356 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                pickup_time        dropoff_time  trip_distance  \\\n",
       "2081085 2022-12-18 14:00:25 2022-12-18 14:24:30           4.20   \n",
       "1182531 2022-12-10 19:00:09 2022-12-10 19:17:08           1.35   \n",
       "474122  2022-12-04 21:05:39 2022-12-04 21:14:34           1.77   \n",
       "1325629 2022-12-12 08:39:43 2022-12-12 08:48:15           1.54   \n",
       "3148362 2022-12-30 15:52:59 2022-12-30 16:06:11           1.54   \n",
       "...                     ...                 ...            ...   \n",
       "3081215 2022-12-29 19:11:03 2022-12-29 19:24:27           1.10   \n",
       "66867   2022-12-01 16:53:11 2022-12-01 16:58:08           0.96   \n",
       "1065815 2022-12-09 20:47:18 2022-12-09 20:53:25           1.29   \n",
       "2371465 2022-12-21 10:12:25 2022-12-21 10:25:47           1.80   \n",
       "685084  2022-12-06 20:04:11 2022-12-06 20:13:23           0.97   \n",
       "\n",
       "         pick_up_location  drop_off_location  fare_amount  extra  mta_tax  \\\n",
       "2081085                41                 48         18.0    0.0      0.5   \n",
       "1182531               148                107         11.5    0.0      0.5   \n",
       "474122                113                170          8.0    0.5      0.5   \n",
       "1325629               237                161          7.5    0.0      0.5   \n",
       "3148362               237                162         13.5    0.0      0.5   \n",
       "...                   ...                ...          ...    ...      ...   \n",
       "3081215               186                246         11.4    5.0      0.5   \n",
       "66867                 238                236          5.5    1.0      0.5   \n",
       "1065815               237                262          6.5    0.5      0.5   \n",
       "2371465               236                237         12.8    2.5      0.5   \n",
       "685084                170                229          7.5    0.5      0.5   \n",
       "\n",
       "         tip_amount  tolls_amount  improvement_surcharge  total_amount  \\\n",
       "2081085        0.00           0.0                    0.3         21.30   \n",
       "1182531        2.96           0.0                    0.3         17.76   \n",
       "474122         2.36           0.0                    0.3         14.16   \n",
       "1325629        3.24           0.0                    0.3         14.04   \n",
       "3148362        0.00           0.0                    1.0         17.50   \n",
       "...             ...           ...                    ...           ...   \n",
       "3081215        3.60           0.0                    1.0         21.50   \n",
       "66867          1.46           0.0                    0.3          8.76   \n",
       "1065815        2.06           0.0                    0.3         12.36   \n",
       "2371465        2.00           0.0                    1.0         18.80   \n",
       "685084         2.26           0.0                    0.3         13.56   \n",
       "\n",
       "         congestion_surcharge  airport_fee  pick_up_lat  pick_up_lon  \\\n",
       "2081085                   2.5          0.0    40.804334   -73.951292   \n",
       "1182531                   2.5          0.0    40.718938   -73.990896   \n",
       "474122                    2.5          0.0    40.732579   -73.994305   \n",
       "1325629                   2.5          0.0    40.768615   -73.965635   \n",
       "3148362                   2.5          0.0    40.768615   -73.965635   \n",
       "...                       ...          ...          ...          ...   \n",
       "3081215                   2.5          0.0    40.748497   -73.992438   \n",
       "66867                     0.0          0.0    40.791705   -73.973049   \n",
       "1065815                   2.5          0.0    40.768615   -73.965635   \n",
       "2371465                   2.5          0.0    40.780436   -73.957012   \n",
       "685084                    2.5          0.0    40.747746   -73.978492   \n",
       "\n",
       "         drop_off_lat  drop_off_lon  \n",
       "2081085     40.762253    -73.989845  \n",
       "1182531     40.736824    -73.984052  \n",
       "474122      40.747746    -73.978492  \n",
       "1325629     40.758028    -73.977698  \n",
       "3148362     40.756688    -73.972356  \n",
       "...               ...           ...  \n",
       "3081215     40.753309    -74.004015  \n",
       "66867       40.780436    -73.957012  \n",
       "1065815     40.775932    -73.946510  \n",
       "2371465     40.768615    -73.965635  \n",
       "685084      40.756729    -73.965146  \n",
       "\n",
       "[356 rows x 18 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_and_clean_taxi_month(url):\n",
    "    '''\n",
    "    This function does the follows:\n",
    "        1. Drop rows with null values in all columns\n",
    "        2. Ensure dropoff_datetime > pickup_datetime > request_datetime\n",
    "        3. Filter rows with invalid or negative location IDs\n",
    "        4. Remove rows with zero or negative trip durations\n",
    "        5. Remove location outside of  (40.560445, -74.242330) and (40.908524, -73.717047).\n",
    "    '''\n",
    "    \n",
    "    # Keep only the necessary columns\n",
    "    df1=pd.read_parquet(url)\n",
    "    poplulation = df1.shape[0]\n",
    "    sample_size = calculate_sample_size(poplulation)\n",
    "    print(f\"population is {poplulation} and calculated sample size is {sample_size}\")\n",
    "    df1 = df1.sample(n=sample_size)\n",
    "    \n",
    "    df1.columns = (\n",
    "        df1.columns\n",
    "        .str.strip()               \n",
    "        .str.lower()               \n",
    "        .str.replace(' ', '_')     \n",
    "        .str.replace(r'\\W+', '_')  \n",
    "    )\n",
    "    \n",
    "    columns_to_keep = [\n",
    "        \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\",\n",
    "        \"trip_distance\", \"pulocationid\", \"dolocationid\", \"fare_amount\",\t\"extra\",\t\n",
    "        \"mta_tax\", \"tip_amount\", \"tolls_amount\", \"improvement_surcharge\", \"total_amount\", \"congestion_surcharge\", \"airport_fee\"\n",
    "    ]\n",
    "    yellow_data = df1[columns_to_keep]\n",
    "    \n",
    "    yellow_data = yellow_data.rename(columns={\n",
    "        \"vendorid\": \"trip_id\",\n",
    "        \"tpep_pickup_datetime\": \"pickup_time\",\n",
    "        \"tpep_dropoff_datetime\": \"dropoff_time\",\n",
    "        \"pulocationid\": \"pick_up_location\",\n",
    "        \"dolocationid\": \"drop_off_location\"\n",
    "    })\n",
    "    #replace NaN with 0 for airport_fee\n",
    "    yellow_data['airport_fee'] = yellow_data['airport_fee'].fillna(0)\n",
    "\n",
    "    #make sure pickup_time in proper datetime format\n",
    "    yellow_data['pickup_time'] = pd.to_datetime(yellow_data['pickup_time'], errors='coerce')\n",
    "    yellow_data['dropoff_time'] = pd.to_datetime(yellow_data['dropoff_time'], errors='coerce')\n",
    "                                                                  \n",
    "    # 1. Drop rows with null values in all columns\n",
    "    all_taxi_columns = [\"pickup_time\",\t\"dropoff_time\",\t\"trip_distance\", \"pick_up_location\",\"drop_off_location\",\"fare_amount\",\t\"extra\",\t\n",
    "         \"mta_tax\", \"tip_amount\", \"tolls_amount\", \"improvement_surcharge\", \"total_amount\",\"congestion_surcharge\",\"airport_fee\"]\n",
    "    yellow_data = yellow_data.dropna(subset=all_taxi_columns)\n",
    "    \n",
    "    # 2. Ensure dropoff_datetime > pickup_datetime > request_datetime\n",
    "    yellow_data = yellow_data[\n",
    "        (yellow_data['dropoff_time'] > yellow_data['pickup_time']) \n",
    "    ]\n",
    "    \n",
    "    \n",
    "    # 3. Filter rows with invalid or negative location IDs\n",
    "    yellow_data = yellow_data[\n",
    "        (yellow_data['pick_up_location'] > 0 ) &\n",
    "        (yellow_data['drop_off_location'] > 0 )\n",
    "    ]\n",
    "\n",
    "    yellow_data = yellow_data[\n",
    "        (yellow_data['pick_up_location'] < 264 ) &\n",
    "        (yellow_data['drop_off_location'] < 264)\n",
    "    ]\n",
    "    \n",
    "    # 4. Remove rows with zero or negative trip durations\n",
    "    yellow_data = yellow_data[yellow_data['trip_distance'] > 0]\n",
    "    \n",
    "    # 5. Remove location outside of  (40.560445, -74.242330) and (40.908524, -73.717047).\n",
    "    '''\n",
    "    for index, row in yellow_data.iterrows():\n",
    "        # get lat,lon using id\n",
    "        pick_up_coords = lookup_coords_for_taxi_zone_id(row[\"pick_up_location\"], taxi_zones)\n",
    "        drop_off_coords = lookup_coords_for_taxi_zone_id(row[\"drop_off_location\"], taxi_zones)\n",
    "        # mutate id with lat and lon\n",
    "        yellow_data.at[index, \"pick_up_latitude\"] = pick_up_coords[0]\n",
    "        yellow_data.at[index, \"pick_up_longitude\"] = pick_up_coords[1]\n",
    "        yellow_data.at[index, \"drop_off_latitude\"] = drop_off_coords[0]\n",
    "        yellow_data.at[index, \"drop_off_longitude\"] = drop_off_coords[1]\n",
    "    '''\n",
    "    lat_min, lon_min = 40.560445, -74.242330\n",
    "    lat_max, lon_max = 40.908524, -73.717047\n",
    "    \n",
    "    yellow_data[\"pick_up_coords\"] = yellow_data[\"pick_up_location\"].apply(get_coords)\n",
    "    yellow_data[\"drop_off_coords\"] = yellow_data[\"drop_off_location\"].apply(get_coords)\n",
    "    \n",
    "    def is_within_bounding_box(coords):\n",
    "        lat, lon = coords\n",
    "        return lat_min <= lat <= lat_max and lon_min <= lon <= lon_max\n",
    "    \n",
    "    pick_up_filter = yellow_data[\"pick_up_coords\"].map(is_within_bounding_box)\n",
    "    drop_off_filter = yellow_data[\"drop_off_coords\"].map(is_within_bounding_box)\n",
    "    \n",
    "    yellow_data = yellow_data[pick_up_filter & drop_off_filter]\n",
    "    \n",
    "    \n",
    "    #Coordinates to lat and lon\n",
    "    def split_coords(coords):\n",
    "        if isinstance(coords, tuple):\n",
    "            return coords  \n",
    "        else:\n",
    "            lat, lon = coords.strip(\"()\").split(\",\")\n",
    "            return float(lat), float(lon)\n",
    "\n",
    "# Add lon and lat to dataframe\n",
    "    if \"pick_up_coords\" in yellow_data.columns and \"drop_off_coords\" in yellow_data.columns:\n",
    "        yellow_data[['pick_up_lat', 'pick_up_lon']] = yellow_data['pick_up_coords'].apply(pd.Series)\n",
    "        yellow_data[['drop_off_lat', 'drop_off_lon']] = yellow_data['drop_off_coords'].apply(pd.Series)\n",
    "   \n",
    "        yellow_data = yellow_data.drop(columns=['pick_up_coords', 'drop_off_coords'])\n",
    "    return yellow_data\n",
    "\n",
    "a = get_and_clean_taxi_month('yellow_tripdata_2022-12.parquet')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cfcf6f62-3053-4f0a-bb88-607170cd6944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_taxi_data(taxi_urls):\n",
    "    all_taxi_dataframes = []\n",
    "    for taxi_url in taxi_urls:\n",
    "        # maybe: first try to see if you've downloaded this exact\n",
    "        # file already and saved it before trying again\n",
    "        dataframe = get_and_clean_taxi_month(taxi_url)\n",
    "        # maybe: if the file hasn't been saved, save it so you can\n",
    "        # avoid re-downloading it if you re-run the function\n",
    "        print(\"Complete cleaning: \", taxi_url)\n",
    "        all_taxi_dataframes.append(dataframe)\n",
    "        \n",
    "    # create one gigantic dataframe with data from every month needed\n",
    "    taxi_data = pd.concat(all_taxi_dataframes)\n",
    "\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "200776ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_taxi_data():\n",
    "    all_urls = get_all_urls_from_tlc_page(TLC_URL)\n",
    "    all_parquet_urls = filter_parquet_urls(all_urls)\n",
    "    correct_urls = select_parquet(all_parquet_urls)\n",
    "    taxi_url_new=select_yellow(correct_urls)\n",
    "    taxi_data = get_and_clean_taxi_data(taxi_url_new)\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aba292-e65d-4d0a-a618-b654cec08e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "876bd645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "population is 2964624 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet \n",
      "population is 3007526 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-02.parquet \n",
      "population is 3582628 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-03.parquet \n",
      "population is 3514289 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-04.parquet\n",
      "population is 3723833 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-05.parquet\n",
      "population is 3539193 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-06.parquet\n",
      "population is 3076903 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-07.parquet\n",
      "population is 2979183 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-08.parquet\n",
      "population is 3066766 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet\n",
      "population is 2913955 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet\n",
      "population is 3403766 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-03.parquet\n",
      "population is 3288250 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-04.parquet\n",
      "population is 3513649 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-05.parquet \n",
      "population is 3307234 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-06.parquet\n",
      "population is 2907108 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-07.parquet \n",
      "population is 2824209 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-08.parquet \n",
      "population is 2846722 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-09.parquet \n",
      "population is 3522285 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-10.parquet \n",
      "population is 3339715 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-11.parquet \n",
      "population is 3376567 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-12.parquet\n",
      "population is 2463931 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet\n",
      "population is 2979431 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet\n",
      "population is 3627882 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-03.parquet\n",
      "population is 3599920 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-04.parquet\n",
      "population is 3588295 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-05.parquet\n",
      "population is 3558124 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-06.parquet\n",
      "population is 3174394 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-07.parquet\n",
      "population is 3152677 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-08.parquet\n",
      "population is 3183767 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-09.parquet\n",
      "population is 3675411 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-10.parquet\n",
      "population is 3252717 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-11.parquet\n",
      "population is 3399549 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-12.parquet\n",
      "population is 1369769 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-01.parquet\n",
      "population is 1371709 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet\n",
      "population is 1925152 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-03.parquet\n",
      "population is 2171187 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-04.parquet\n",
      "population is 2507109 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-05.parquet\n",
      "population is 2834264 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-06.parquet\n",
      "population is 2821746 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-07.parquet\n",
      "population is 2788757 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-08.parquet\n",
      "population is 2963793 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-09.parquet\n",
      "population is 3463504 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-10.parquet\n",
      "population is 3472949 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-11.parquet\n",
      "population is 3214369 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-12.parquet\n",
      "population is 6405008 and calculated sample size is 385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11211\\AppData\\Local\\Temp\\ipykernel_6424\\4117364428.py:41: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  yellow_data['airport_fee'] = yellow_data['airport_fee'].fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-01.parquet\n",
      "population is 6299367 and calculated sample size is 385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11211\\AppData\\Local\\Temp\\ipykernel_6424\\4117364428.py:41: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  yellow_data['airport_fee'] = yellow_data['airport_fee'].fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-02.parquet\n",
      "population is 3007687 and calculated sample size is 385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11211\\AppData\\Local\\Temp\\ipykernel_6424\\4117364428.py:41: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  yellow_data['airport_fee'] = yellow_data['airport_fee'].fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-03.parquet\n",
      "population is 238073 and calculated sample size is 385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11211\\AppData\\Local\\Temp\\ipykernel_6424\\4117364428.py:41: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  yellow_data['airport_fee'] = yellow_data['airport_fee'].fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-04.parquet\n",
      "population is 348415 and calculated sample size is 385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11211\\AppData\\Local\\Temp\\ipykernel_6424\\4117364428.py:41: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  yellow_data['airport_fee'] = yellow_data['airport_fee'].fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-05.parquet\n",
      "population is 549797 and calculated sample size is 385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11211\\AppData\\Local\\Temp\\ipykernel_6424\\4117364428.py:41: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  yellow_data['airport_fee'] = yellow_data['airport_fee'].fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-06.parquet\n",
      "population is 800412 and calculated sample size is 385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11211\\AppData\\Local\\Temp\\ipykernel_6424\\4117364428.py:41: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  yellow_data['airport_fee'] = yellow_data['airport_fee'].fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-07.parquet\n",
      "population is 1007286 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-08.parquet\n",
      "population is 1341017 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-09.parquet\n",
      "population is 1681132 and calculated sample size is 385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11211\\AppData\\Local\\Temp\\ipykernel_6424\\4117364428.py:41: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  yellow_data['airport_fee'] = yellow_data['airport_fee'].fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-10.parquet\n",
      "population is 1509000 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-11.parquet\n",
      "population is 1461898 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-12.parquet\n"
     ]
    }
   ],
   "source": [
    "taxi_data = get_taxi_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "10ebd75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_time</th>\n",
       "      <th>dropoff_time</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pick_up_location</th>\n",
       "      <th>drop_off_location</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>pick_up_lat</th>\n",
       "      <th>pick_up_lon</th>\n",
       "      <th>drop_off_lat</th>\n",
       "      <th>drop_off_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1932305</th>\n",
       "      <td>2024-01-22 19:05:09</td>\n",
       "      <td>2024-01-22 19:23:44</td>\n",
       "      <td>6.66</td>\n",
       "      <td>233</td>\n",
       "      <td>231</td>\n",
       "      <td>28.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.94</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.749914</td>\n",
       "      <td>-73.970443</td>\n",
       "      <td>40.717773</td>\n",
       "      <td>-74.007880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157302</th>\n",
       "      <td>2024-01-14 09:06:21</td>\n",
       "      <td>2024-01-14 09:18:33</td>\n",
       "      <td>4.49</td>\n",
       "      <td>140</td>\n",
       "      <td>166</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.40</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.765484</td>\n",
       "      <td>-73.954739</td>\n",
       "      <td>40.809457</td>\n",
       "      <td>-73.961764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291875</th>\n",
       "      <td>2024-01-26 13:53:49</td>\n",
       "      <td>2024-01-26 14:02:51</td>\n",
       "      <td>1.07</td>\n",
       "      <td>230</td>\n",
       "      <td>246</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.60</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.759818</td>\n",
       "      <td>-73.984196</td>\n",
       "      <td>40.753309</td>\n",
       "      <td>-74.004015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694766</th>\n",
       "      <td>2024-01-20 01:09:56</td>\n",
       "      <td>2024-01-20 01:15:24</td>\n",
       "      <td>1.27</td>\n",
       "      <td>68</td>\n",
       "      <td>50</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.90</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.748428</td>\n",
       "      <td>-73.999917</td>\n",
       "      <td>40.766238</td>\n",
       "      <td>-73.995135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509429</th>\n",
       "      <td>2024-01-06 22:10:22</td>\n",
       "      <td>2024-01-06 22:29:31</td>\n",
       "      <td>3.82</td>\n",
       "      <td>90</td>\n",
       "      <td>239</td>\n",
       "      <td>21.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.20</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.742279</td>\n",
       "      <td>-73.996971</td>\n",
       "      <td>40.783961</td>\n",
       "      <td>-73.978632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pickup_time        dropoff_time  trip_distance  \\\n",
       "1932305 2024-01-22 19:05:09 2024-01-22 19:23:44           6.66   \n",
       "1157302 2024-01-14 09:06:21 2024-01-14 09:18:33           4.49   \n",
       "2291875 2024-01-26 13:53:49 2024-01-26 14:02:51           1.07   \n",
       "1694766 2024-01-20 01:09:56 2024-01-20 01:15:24           1.27   \n",
       "509429  2024-01-06 22:10:22 2024-01-06 22:29:31           3.82   \n",
       "\n",
       "         pick_up_location  drop_off_location  fare_amount  extra  mta_tax  \\\n",
       "1932305               233                231         28.9    2.5      0.5   \n",
       "1157302               140                166         20.5    0.0      0.5   \n",
       "2291875               230                246          9.3    0.0      0.5   \n",
       "1694766                68                 50          7.9    1.0      0.5   \n",
       "509429                 90                239         21.2    1.0      0.5   \n",
       "\n",
       "         tip_amount  tolls_amount  improvement_surcharge  total_amount  \\\n",
       "1932305        3.54           0.0                    1.0         38.94   \n",
       "1157302        4.90           0.0                    1.0         29.40   \n",
       "2291875        1.30           0.0                    1.0         14.60   \n",
       "1694766        0.00           0.0                    1.0         12.90   \n",
       "509429         0.00           0.0                    1.0         26.20   \n",
       "\n",
       "         congestion_surcharge  airport_fee  pick_up_lat  pick_up_lon  \\\n",
       "1932305                   2.5          0.0    40.749914   -73.970443   \n",
       "1157302                   2.5          0.0    40.765484   -73.954739   \n",
       "2291875                   2.5          0.0    40.759818   -73.984196   \n",
       "1694766                   2.5          0.0    40.748428   -73.999917   \n",
       "509429                    2.5          0.0    40.742279   -73.996971   \n",
       "\n",
       "         drop_off_lat  drop_off_lon  \n",
       "1932305     40.717773    -74.007880  \n",
       "1157302     40.809457    -73.961764  \n",
       "2291875     40.753309    -74.004015  \n",
       "1694766     40.766238    -73.995135  \n",
       "509429      40.783961    -73.978632  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c9da7089-3f6b-4f93-a22e-76bf554daca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 19820 entries, 1932305 to 158626\n",
      "Data columns (total 18 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   pickup_time            19820 non-null  datetime64[us]\n",
      " 1   dropoff_time           19820 non-null  datetime64[us]\n",
      " 2   trip_distance          19820 non-null  float64       \n",
      " 3   pick_up_location       19820 non-null  int64         \n",
      " 4   drop_off_location      19820 non-null  int64         \n",
      " 5   fare_amount            19820 non-null  float64       \n",
      " 6   extra                  19820 non-null  float64       \n",
      " 7   mta_tax                19820 non-null  float64       \n",
      " 8   tip_amount             19820 non-null  float64       \n",
      " 9   tolls_amount           19820 non-null  float64       \n",
      " 10  improvement_surcharge  19820 non-null  float64       \n",
      " 11  total_amount           19820 non-null  float64       \n",
      " 12  congestion_surcharge   19820 non-null  float64       \n",
      " 13  airport_fee            19820 non-null  float64       \n",
      " 14  pick_up_lat            19820 non-null  float64       \n",
      " 15  pick_up_lon            19820 non-null  float64       \n",
      " 16  drop_off_lat           19820 non-null  float64       \n",
      " 17  drop_off_lon           19820 non-null  float64       \n",
      "dtypes: datetime64[us](2), float64(14), int64(2)\n",
      "memory usage: 2.9 MB\n"
     ]
    }
   ],
   "source": [
    "taxi_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "50c85e25-6416-4c16-b98c-09596cdc6865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_time</th>\n",
       "      <th>dropoff_time</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pick_up_location</th>\n",
       "      <th>drop_off_location</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>pick_up_lat</th>\n",
       "      <th>pick_up_lon</th>\n",
       "      <th>drop_off_lat</th>\n",
       "      <th>drop_off_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19820</td>\n",
       "      <td>19820</td>\n",
       "      <td>19820.000000</td>\n",
       "      <td>19820.000000</td>\n",
       "      <td>19820.000000</td>\n",
       "      <td>19820.000000</td>\n",
       "      <td>19820.000000</td>\n",
       "      <td>19820.000000</td>\n",
       "      <td>19820.000000</td>\n",
       "      <td>19820.000000</td>\n",
       "      <td>19820.000000</td>\n",
       "      <td>19820.000000</td>\n",
       "      <td>19820.000000</td>\n",
       "      <td>19820.000000</td>\n",
       "      <td>19820.000000</td>\n",
       "      <td>19820.000000</td>\n",
       "      <td>19820.000000</td>\n",
       "      <td>19820.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2022-05-01 13:39:08.862562</td>\n",
       "      <td>2022-05-01 13:55:02.641069</td>\n",
       "      <td>3.144545</td>\n",
       "      <td>164.823865</td>\n",
       "      <td>161.813824</td>\n",
       "      <td>14.691682</td>\n",
       "      <td>1.264306</td>\n",
       "      <td>0.490383</td>\n",
       "      <td>2.729930</td>\n",
       "      <td>0.419822</td>\n",
       "      <td>0.541650</td>\n",
       "      <td>21.816583</td>\n",
       "      <td>2.286201</td>\n",
       "      <td>0.082820</td>\n",
       "      <td>40.753939</td>\n",
       "      <td>-73.967261</td>\n",
       "      <td>40.755680</td>\n",
       "      <td>-73.971348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2020-01-01 00:41:15</td>\n",
       "      <td>2020-01-01 00:59:40</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-87.700000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-12.800000</td>\n",
       "      <td>-6.940000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-90.950000</td>\n",
       "      <td>-2.500000</td>\n",
       "      <td>-1.750000</td>\n",
       "      <td>40.580922</td>\n",
       "      <td>-74.174000</td>\n",
       "      <td>40.576961</td>\n",
       "      <td>-74.174000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2021-03-07 12:26:33.750000</td>\n",
       "      <td>2021-03-07 12:34:05.250000</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>12.360000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.740439</td>\n",
       "      <td>-73.989845</td>\n",
       "      <td>40.740337</td>\n",
       "      <td>-73.989845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022-05-02 10:12:40</td>\n",
       "      <td>2022-05-02 10:23:40.500000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>16.440000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.758028</td>\n",
       "      <td>-73.977698</td>\n",
       "      <td>40.758028</td>\n",
       "      <td>-73.977698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023-06-26 11:59:58.250000</td>\n",
       "      <td>2023-06-26 12:10:50</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>16.300000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.760000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.773633</td>\n",
       "      <td>-73.965146</td>\n",
       "      <td>40.774376</td>\n",
       "      <td>-73.959635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024-08-31 20:44:37</td>\n",
       "      <td>2024-08-31 20:55:06</td>\n",
       "      <td>44.600000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>110.700000</td>\n",
       "      <td>35.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>327.300000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>40.897932</td>\n",
       "      <td>-73.764506</td>\n",
       "      <td>40.899529</td>\n",
       "      <td>-73.726655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000513</td>\n",
       "      <td>64.532881</td>\n",
       "      <td>69.830824</td>\n",
       "      <td>13.965469</td>\n",
       "      <td>1.526549</td>\n",
       "      <td>0.092530</td>\n",
       "      <td>3.316784</td>\n",
       "      <td>1.794938</td>\n",
       "      <td>0.353279</td>\n",
       "      <td>17.897944</td>\n",
       "      <td>0.754263</td>\n",
       "      <td>0.351786</td>\n",
       "      <td>0.030973</td>\n",
       "      <td>0.044708</td>\n",
       "      <td>0.031946</td>\n",
       "      <td>0.035817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      pickup_time                dropoff_time  trip_distance  \\\n",
       "count                       19820                       19820   19820.000000   \n",
       "mean   2022-05-01 13:39:08.862562  2022-05-01 13:55:02.641069       3.144545   \n",
       "min           2020-01-01 00:41:15         2020-01-01 00:59:40       0.010000   \n",
       "25%    2021-03-07 12:26:33.750000  2021-03-07 12:34:05.250000       1.040000   \n",
       "50%           2022-05-02 10:12:40  2022-05-02 10:23:40.500000       1.750000   \n",
       "75%    2023-06-26 11:59:58.250000         2023-06-26 12:10:50       3.200000   \n",
       "max           2024-08-31 20:44:37         2024-08-31 20:55:06      44.600000   \n",
       "std                           NaN                         NaN       4.000513   \n",
       "\n",
       "       pick_up_location  drop_off_location   fare_amount         extra  \\\n",
       "count      19820.000000       19820.000000  19820.000000  19820.000000   \n",
       "mean         164.823865         161.813824     14.691682      1.264306   \n",
       "min            1.000000           1.000000    -87.700000     -6.000000   \n",
       "25%          132.000000         112.000000      7.000000      0.000000   \n",
       "50%          162.000000         162.000000     10.500000      1.000000   \n",
       "75%          234.000000         234.000000     16.300000      2.500000   \n",
       "max          263.000000         263.000000    300.000000     11.750000   \n",
       "std           64.532881          69.830824     13.965469      1.526549   \n",
       "\n",
       "            mta_tax    tip_amount  tolls_amount  improvement_surcharge  \\\n",
       "count  19820.000000  19820.000000  19820.000000           19820.000000   \n",
       "mean       0.490383      2.729930      0.419822               0.541650   \n",
       "min       -0.500000    -12.800000     -6.940000              -1.000000   \n",
       "25%        0.500000      0.000000      0.000000               0.300000   \n",
       "50%        0.500000      2.160000      0.000000               0.300000   \n",
       "75%        0.500000      3.500000      0.000000               1.000000   \n",
       "max        0.800000    110.700000     35.250000               1.000000   \n",
       "std        0.092530      3.316784      1.794938               0.353279   \n",
       "\n",
       "       total_amount  congestion_surcharge   airport_fee   pick_up_lat  \\\n",
       "count  19820.000000          19820.000000  19820.000000  19820.000000   \n",
       "mean      21.816583              2.286201      0.082820     40.753939   \n",
       "min      -90.950000             -2.500000     -1.750000     40.580922   \n",
       "25%       12.360000              2.500000      0.000000     40.740439   \n",
       "50%       16.440000              2.500000      0.000000     40.758028   \n",
       "75%       23.760000              2.500000      0.000000     40.773633   \n",
       "max      327.300000              2.500000      1.750000     40.897932   \n",
       "std       17.897944              0.754263      0.351786      0.030973   \n",
       "\n",
       "        pick_up_lon  drop_off_lat  drop_off_lon  \n",
       "count  19820.000000  19820.000000  19820.000000  \n",
       "mean     -73.967261     40.755680    -73.971348  \n",
       "min      -74.174000     40.576961    -74.174000  \n",
       "25%      -73.989845     40.740337    -73.989845  \n",
       "50%      -73.977698     40.758028    -73.977698  \n",
       "75%      -73.965146     40.774376    -73.959635  \n",
       "max      -73.764506     40.899529    -73.726655  \n",
       "std        0.044708      0.031946      0.035817  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094b4d6d",
   "metadata": {},
   "source": [
    "### Processing Uber Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "07574983-f41d-4cd6-8f70-489493089b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_uber_month(url):\n",
    "\n",
    "    df_uber=pd.read_parquet(url)\n",
    "    poplulation = df_uber.shape[0]\n",
    "    sample_size = calculate_sample_size(poplulation)\n",
    "    print(f\"population is {poplulation} and calculated sample size is {sample_size}\")\n",
    "    df_uber = df_uber.sample(n=sample_size)\n",
    "    \n",
    "    # Define columns to keep\n",
    "    uber_columns = [\n",
    "        \"hvfhs_license_num\", \n",
    "         \"pickup_datetime\",\n",
    "        \"dropoff_datetime\", \"PULocationID\", \"DOLocationID\", \"trip_miles\",\t\n",
    "        \"sales_tax\", \"congestion_surcharge\", \"airport_fee\",\t\"tips\",\t\"driver_pay\",\"base_passenger_fare\", \n",
    "        \"tolls\"\n",
    "    ]\n",
    "    # Keep only the necessary columns\n",
    "    uber_cleaned1 = df_uber[uber_columns]\n",
    "    uber_cleaned = uber_cleaned1[uber_cleaned1['hvfhs_license_num'] == 'HV0003']\n",
    "    uber_cleaned.columns = (\n",
    "        uber_cleaned.columns\n",
    "        .str.strip()               # Remove leading/trailing spaces\n",
    "        .str.lower()               # Convert to lowercase\n",
    "        .str.replace(' ', '_')     # Replace spaces with underscores\n",
    "        .str.replace(r'\\W+', '_')  # Replace non-word characters with underscores\n",
    "    )\n",
    "    uber_cleaned = uber_cleaned.rename(columns={\n",
    "        \"hvfhs_license_num\": \"uber_license_num\",\n",
    "        \"pulocationid\": \"pick_up_location\",\n",
    "        \"dolocationid\": \"drop_off_location\"\n",
    "    })\n",
    "    \n",
    "    uber_cleaned['airport_fee'] =uber_cleaned['airport_fee'].fillna(0)\n",
    "    \n",
    "    #Remove invalid datapoints\n",
    "    # 1. Drop rows with null values in all columns\n",
    "    all_columns = [\"uber_license_num\",\t\"pickup_datetime\", \n",
    "                   \"dropoff_datetime\", \"pick_up_location\", \"drop_off_location\",\"trip_miles\",\t\n",
    "                    \"sales_tax\", \"congestion_surcharge\", \"airport_fee\",\t\"tips\",\t\"driver_pay\",\"base_passenger_fare\", \"tolls\"]\n",
    "    uber_cleaned = uber_cleaned.dropna(subset=all_columns)\n",
    "    \n",
    "    # 2. Ensure dropoff_datetime > pickup_datetime > request_datetime\n",
    "    uber_cleaned = uber_cleaned[\n",
    "        (uber_cleaned['dropoff_datetime'] > uber_cleaned['pickup_datetime']) \n",
    "    ]\n",
    "    \n",
    "    # 3. Filter rows with invalid or negative location IDs\n",
    "    uber_cleaned = uber_cleaned[\n",
    "        (uber_cleaned['pick_up_location'] > 0) &\n",
    "        (uber_cleaned['drop_off_location'] > 0)\n",
    "    ]\n",
    "\n",
    "    uber_cleaned = uber_cleaned[\n",
    "        (uber_cleaned['pick_up_location'] < 264) &\n",
    "        (uber_cleaned['drop_off_location'] < 264)\n",
    "    ]\n",
    "\n",
    "    # 4. Remove rows with zero or negative trip durations\n",
    "    uber_cleaned['trip_duration'] = (\n",
    "        pd.to_datetime(uber_cleaned['dropoff_datetime']) - pd.to_datetime(uber_cleaned['pickup_datetime'])\n",
    "    ).dt.total_seconds()\n",
    "    uber_cleaned = uber_cleaned[uber_cleaned['trip_duration'] > 0]\n",
    "\n",
    "    # 5. Remove location outside of  (40.560445, -74.242330) and (40.908524, -73.717047).\n",
    "    '''\n",
    "    for index, row in uber_cleaned.iterrows():\n",
    "        # get lat,lon using id\n",
    "        pick_up_coords = lookup_coords_for_taxi_zone_id(row[\"pick_up_location\"], taxi_zones)\n",
    "        drop_off_coords = lookup_coords_for_taxi_zone_id(row[\"drop_off_location\"], taxi_zones)\n",
    "        # mutate id with lat and lon\n",
    "        uber_cleaned.at[index, \"pick_up_latitude\"] = pick_up_coords[0]\n",
    "        uber_cleaned.at[index, \"pick_up_longitude\"] = pick_up_coords[1]\n",
    "        uber_cleaned.at[index, \"drop_off_latitude\"] = drop_off_coords[0]\n",
    "        uber_cleaned.at[index, \"drop_off_longitude\"] = drop_off_coords[1]\n",
    "    '''\n",
    "    lat_min, lon_min = 40.560445, -74.242330\n",
    "    lat_max, lon_max = 40.908524, -73.717047\n",
    "    \n",
    "    def is_within_bounding_box(coords):\n",
    "        lat, lon = coords\n",
    "        return lat_min <= lat <= lat_max and lon_min <= lon <= lon_max\n",
    "    uber_cleaned[\"pick_up_coords\"] = uber_cleaned[\"pick_up_location\"].apply(get_coords)\n",
    "    uber_cleaned[\"drop_off_coords\"] = uber_cleaned[\"drop_off_location\"].apply(get_coords)\n",
    "\n",
    "    pick_up_filter = uber_cleaned[\"pick_up_coords\"].map(is_within_bounding_box)\n",
    "    drop_off_filter = uber_cleaned[\"drop_off_coords\"].map(is_within_bounding_box)\n",
    "\n",
    "    #Coordinates to lat and lon\n",
    "    def split_coords(coords):\n",
    "        if isinstance(coords, tuple):\n",
    "            return coords  \n",
    "        else:\n",
    "            lat, lon = coords.strip(\"()\").split(\",\")\n",
    "            return float(lat), float(lon)\n",
    "\n",
    "    # Add lon and lat to dataframe\n",
    "    uber_cleaned[['pick_up_lat', 'pick_up_lon']] = uber_cleaned['pick_up_coords'].apply(pd.Series)\n",
    "    uber_cleaned[['drop_off_lat', 'drop_off_lon']] = uber_cleaned['drop_off_coords'].apply(pd.Series)\n",
    "    uber_cleaned = uber_cleaned.drop(columns=['pick_up_coords', 'drop_off_coords'])\n",
    "    \n",
    "    return uber_cleaned\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1b3d85ff-313c-41a2-9a46-261a9a2bb10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_uber_data(uber_urls):\n",
    "    all_uber_dataframes = []\n",
    "    \n",
    "    for uber_url in uber_urls:\n",
    "        # maybe: first try to see if you've downloaded this exact\n",
    "        # file already and saved it before trying again\n",
    "        dataframe = get_and_clean_uber_month(uber_url)\n",
    "        # maybe: if the file hasn't been saved, save it so you can\n",
    "        # avoid re-downloading it if you re-run the function\n",
    "        \n",
    "        all_uber_dataframes.append(dataframe)\n",
    "        print(\"Complete cleaning: \", uber_url)\n",
    "        \n",
    "    # create one gigantic dataframe with data from every month needed\n",
    "    uber_data = pd.concat(all_uber_dataframes)\n",
    "    return uber_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7c58e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_uber_data():\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f836f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uber_data():\n",
    "    all_urls = get_all_urls_from_tlc_page(TLC_URL)\n",
    "    all_parquet_urls = filter_parquet_urls(all_urls)\n",
    "    correct_urls = select_parquet(all_parquet_urls)\n",
    "    uber_url_new=select_fhvhv(correct_urls)\n",
    "    uber_data = get_and_clean_uber_data(uber_url_new)\n",
    "    return uber_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9c2bd13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "population is 19663930 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-01.parquet \n",
      "population is 19359148 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-02.parquet \n",
      "population is 21280788 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-03.parquet \n",
      "population is 19733038 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-04.parquet\n",
      "population is 20704538 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-05.parquet\n",
      "population is 20123226 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-06.parquet\n",
      "population is 19182934 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-07.parquet\n",
      "population is 19128392 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-08.parquet\n",
      "population is 18479031 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-01.parquet\n",
      "population is 17960971 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-02.parquet\n",
      "population is 20413539 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-03.parquet \n",
      "population is 19144903 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-04.parquet\n",
      "population is 19847676 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-05.parquet \n",
      "population is 19366619 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-06.parquet\n",
      "population is 19132131 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-07.parquet \n",
      "population is 18322150 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-08.parquet \n",
      "population is 19851123 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-09.parquet \n",
      "population is 20186330 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-10.parquet \n",
      "population is 19269250 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-11.parquet \n",
      "population is 20516297 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-12.parquet \n",
      "population is 14751591 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-01.parquet\n",
      "population is 16019283 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-02.parquet\n",
      "population is 18453548 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-03.parquet\n",
      "population is 17752561 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-04.parquet\n",
      "population is 18157335 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-05.parquet\n",
      "population is 17780075 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-06.parquet\n",
      "population is 17464619 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-07.parquet\n",
      "population is 17185687 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-08.parquet\n",
      "population is 17793551 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-09.parquet\n",
      "population is 19306090 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-10.parquet\n",
      "population is 18085896 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-11.parquet\n",
      "population is 19665847 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-12.parquet\n",
      "population is 11908468 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-01.parquet\n",
      "population is 11613942 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-02.parquet\n",
      "population is 14227393 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-03.parquet\n",
      "population is 14111371 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-04.parquet\n",
      "population is 14719171 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-05.parquet\n",
      "population is 14961892 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-06.parquet\n",
      "population is 15027174 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-07.parquet\n",
      "population is 14499696 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-08.parquet\n",
      "population is 14886055 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-09.parquet\n",
      "population is 16545356 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-10.parquet\n",
      "population is 16041639 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-11.parquet\n",
      "population is 16054495 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-12.parquet\n",
      "population is 20569368 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-01.parquet\n",
      "population is 21725100 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-02.parquet\n",
      "population is 13392928 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-03.parquet\n",
      "population is 4312909 and calculated sample size is 385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11211\\AppData\\Local\\Temp\\ipykernel_6424\\203256557.py:33: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  uber_cleaned['airport_fee'] =uber_cleaned['airport_fee'].fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-04.parquet\n",
      "population is 6089999 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-05.parquet\n",
      "population is 7555193 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-06.parquet\n",
      "population is 9958454 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-07.parquet\n",
      "population is 11096852 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-08.parquet\n",
      "population is 12106669 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-09.parquet\n",
      "population is 13268411 and calculated sample size is 385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11211\\AppData\\Local\\Temp\\ipykernel_6424\\203256557.py:33: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  uber_cleaned['airport_fee'] =uber_cleaned['airport_fee'].fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-10.parquet\n",
      "population is 11596865 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-11.parquet\n",
      "population is 11637123 and calculated sample size is 385\n",
      "Complete cleaning:  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-12.parquet\n"
     ]
    }
   ],
   "source": [
    "uber_data = get_uber_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "339997e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uber_license_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pick_up_location</th>\n",
       "      <th>drop_off_location</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>sales_tax</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>tips</th>\n",
       "      <th>driver_pay</th>\n",
       "      <th>base_passenger_fare</th>\n",
       "      <th>tolls</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>pick_up_lat</th>\n",
       "      <th>pick_up_lon</th>\n",
       "      <th>drop_off_lat</th>\n",
       "      <th>drop_off_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5015332</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2024-01-09 17:03:05</td>\n",
       "      <td>2024-01-09 17:18:47</td>\n",
       "      <td>112</td>\n",
       "      <td>7</td>\n",
       "      <td>2.19</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.88</td>\n",
       "      <td>13.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>942.0</td>\n",
       "      <td>40.729506</td>\n",
       "      <td>-73.949540</td>\n",
       "      <td>40.761493</td>\n",
       "      <td>-73.919694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11789217</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2024-01-19 23:35:31</td>\n",
       "      <td>2024-01-20 00:00:13</td>\n",
       "      <td>164</td>\n",
       "      <td>152</td>\n",
       "      <td>7.33</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.56</td>\n",
       "      <td>23.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1482.0</td>\n",
       "      <td>40.748575</td>\n",
       "      <td>-73.985156</td>\n",
       "      <td>40.817975</td>\n",
       "      <td>-73.953782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8838746</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2024-01-15 15:04:02</td>\n",
       "      <td>2024-01-15 15:13:23</td>\n",
       "      <td>76</td>\n",
       "      <td>63</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.18</td>\n",
       "      <td>9.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>561.0</td>\n",
       "      <td>40.660935</td>\n",
       "      <td>-73.876821</td>\n",
       "      <td>40.683840</td>\n",
       "      <td>-73.878173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2847174</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2024-01-06 00:13:10</td>\n",
       "      <td>2024-01-06 00:46:36</td>\n",
       "      <td>205</td>\n",
       "      <td>159</td>\n",
       "      <td>18.66</td>\n",
       "      <td>4.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.19</td>\n",
       "      <td>46.77</td>\n",
       "      <td>6.94</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>40.691201</td>\n",
       "      <td>-73.763146</td>\n",
       "      <td>40.818260</td>\n",
       "      <td>-73.912849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4215586</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2024-01-08 08:12:38</td>\n",
       "      <td>2024-01-08 08:55:49</td>\n",
       "      <td>66</td>\n",
       "      <td>132</td>\n",
       "      <td>18.24</td>\n",
       "      <td>6.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.32</td>\n",
       "      <td>75.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2591.0</td>\n",
       "      <td>40.702259</td>\n",
       "      <td>-73.985702</td>\n",
       "      <td>40.646985</td>\n",
       "      <td>-73.786533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         uber_license_num     pickup_datetime    dropoff_datetime  \\\n",
       "5015332            HV0003 2024-01-09 17:03:05 2024-01-09 17:18:47   \n",
       "11789217           HV0003 2024-01-19 23:35:31 2024-01-20 00:00:13   \n",
       "8838746            HV0003 2024-01-15 15:04:02 2024-01-15 15:13:23   \n",
       "2847174            HV0003 2024-01-06 00:13:10 2024-01-06 00:46:36   \n",
       "4215586            HV0003 2024-01-08 08:12:38 2024-01-08 08:55:49   \n",
       "\n",
       "          pick_up_location  drop_off_location  trip_miles  sales_tax  \\\n",
       "5015332                112                  7        2.19       1.22   \n",
       "11789217               164                152        7.33       2.12   \n",
       "8838746                 76                 63        1.45       0.87   \n",
       "2847174                205                159       18.66       4.77   \n",
       "4215586                 66                132       18.24       6.92   \n",
       "\n",
       "          congestion_surcharge  airport_fee  tips  driver_pay  \\\n",
       "5015332                   0.00          0.0   0.0        5.88   \n",
       "11789217                  2.75          0.0   0.0       23.56   \n",
       "8838746                   0.00          0.0   0.0        7.18   \n",
       "2847174                   0.00          0.0   0.0       44.19   \n",
       "4215586                   0.00          2.5   0.0       48.32   \n",
       "\n",
       "          base_passenger_fare  tolls  trip_duration  pick_up_lat  pick_up_lon  \\\n",
       "5015332                 13.75   0.00          942.0    40.729506   -73.949540   \n",
       "11789217                23.85   0.00         1482.0    40.748575   -73.985156   \n",
       "8838746                  9.79   0.00          561.0    40.660935   -73.876821   \n",
       "2847174                 46.77   6.94         2006.0    40.691201   -73.763146   \n",
       "4215586                 75.43   0.00         2591.0    40.702259   -73.985702   \n",
       "\n",
       "          drop_off_lat  drop_off_lon  \n",
       "5015332      40.761493    -73.919694  \n",
       "11789217     40.817975    -73.953782  \n",
       "8838746      40.683840    -73.878173  \n",
       "2847174      40.818260    -73.912849  \n",
       "4215586      40.646985    -73.786533  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "74d783db-e527-4847-bf70-2d7428ea3897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 15145 entries, 5015332 to 2648156\n",
      "Data columns (total 18 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   uber_license_num      15145 non-null  object        \n",
      " 1   pickup_datetime       15145 non-null  datetime64[us]\n",
      " 2   dropoff_datetime      15145 non-null  datetime64[us]\n",
      " 3   pick_up_location      15145 non-null  int64         \n",
      " 4   drop_off_location     15145 non-null  int64         \n",
      " 5   trip_miles            15145 non-null  float64       \n",
      " 6   sales_tax             15145 non-null  float64       \n",
      " 7   congestion_surcharge  15145 non-null  float64       \n",
      " 8   airport_fee           15145 non-null  float64       \n",
      " 9   tips                  15145 non-null  float64       \n",
      " 10  driver_pay            15145 non-null  float64       \n",
      " 11  base_passenger_fare   15145 non-null  float64       \n",
      " 12  tolls                 15145 non-null  float64       \n",
      " 13  trip_duration         15145 non-null  float64       \n",
      " 14  pick_up_lat           15145 non-null  float64       \n",
      " 15  pick_up_lon           15145 non-null  float64       \n",
      " 16  drop_off_lat          15145 non-null  float64       \n",
      " 17  drop_off_lon          15145 non-null  float64       \n",
      "dtypes: datetime64[us](2), float64(13), int64(2), object(1)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "uber_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6fddeb14-cd70-4e83-8f93-974642c3bea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pick_up_location</th>\n",
       "      <th>drop_off_location</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>sales_tax</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>tips</th>\n",
       "      <th>driver_pay</th>\n",
       "      <th>base_passenger_fare</th>\n",
       "      <th>tolls</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>pick_up_lat</th>\n",
       "      <th>pick_up_lon</th>\n",
       "      <th>drop_off_lat</th>\n",
       "      <th>drop_off_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15145</td>\n",
       "      <td>15145</td>\n",
       "      <td>15145.000000</td>\n",
       "      <td>15145.000000</td>\n",
       "      <td>15145.000000</td>\n",
       "      <td>15145.000000</td>\n",
       "      <td>15145.000000</td>\n",
       "      <td>15145.000000</td>\n",
       "      <td>15145.000000</td>\n",
       "      <td>15145.000000</td>\n",
       "      <td>15145.000000</td>\n",
       "      <td>15145.000000</td>\n",
       "      <td>15145.000000</td>\n",
       "      <td>15145.000000</td>\n",
       "      <td>15145.000000</td>\n",
       "      <td>15145.000000</td>\n",
       "      <td>15145.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2022-05-08 02:16:15.216374</td>\n",
       "      <td>2022-05-08 02:34:11.021525</td>\n",
       "      <td>138.076527</td>\n",
       "      <td>137.171476</td>\n",
       "      <td>4.421297</td>\n",
       "      <td>1.896094</td>\n",
       "      <td>1.063982</td>\n",
       "      <td>0.132965</td>\n",
       "      <td>0.823195</td>\n",
       "      <td>17.004668</td>\n",
       "      <td>21.129109</td>\n",
       "      <td>0.654491</td>\n",
       "      <td>1075.805150</td>\n",
       "      <td>40.729596</td>\n",
       "      <td>-73.920892</td>\n",
       "      <td>40.731798</td>\n",
       "      <td>-73.925946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2020-01-01 01:16:17</td>\n",
       "      <td>2020-01-01 01:42:30</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-15.910000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-74.233534</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-74.233534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2021-03-05 07:53:11</td>\n",
       "      <td>2021-03-05 08:16:01</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>1.540000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.260000</td>\n",
       "      <td>10.510000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>557.000000</td>\n",
       "      <td>40.690787</td>\n",
       "      <td>-73.985156</td>\n",
       "      <td>40.690787</td>\n",
       "      <td>-73.984196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022-05-09 23:03:02</td>\n",
       "      <td>2022-05-09 23:16:07</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>2.840000</td>\n",
       "      <td>1.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.290000</td>\n",
       "      <td>16.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>885.000000</td>\n",
       "      <td>40.737699</td>\n",
       "      <td>-73.948789</td>\n",
       "      <td>40.738324</td>\n",
       "      <td>-73.948522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023-07-08 10:25:05</td>\n",
       "      <td>2023-07-08 10:36:17</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>5.610000</td>\n",
       "      <td>2.370000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.710000</td>\n",
       "      <td>26.360000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1381.000000</td>\n",
       "      <td>40.775965</td>\n",
       "      <td>-73.899735</td>\n",
       "      <td>40.775932</td>\n",
       "      <td>-73.899536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024-08-31 21:42:07</td>\n",
       "      <td>2024-08-31 22:39:49</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>34.270000</td>\n",
       "      <td>18.420000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>46.110000</td>\n",
       "      <td>131.780000</td>\n",
       "      <td>211.340000</td>\n",
       "      <td>46.450000</td>\n",
       "      <td>8534.000000</td>\n",
       "      <td>40.899529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.899529</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.458304</td>\n",
       "      <td>75.408914</td>\n",
       "      <td>4.325343</td>\n",
       "      <td>1.448003</td>\n",
       "      <td>1.334295</td>\n",
       "      <td>0.560936</td>\n",
       "      <td>2.469842</td>\n",
       "      <td>12.397572</td>\n",
       "      <td>15.664609</td>\n",
       "      <td>2.533267</td>\n",
       "      <td>739.205502</td>\n",
       "      <td>0.577492</td>\n",
       "      <td>1.042600</td>\n",
       "      <td>0.473222</td>\n",
       "      <td>0.852350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  pickup_datetime            dropoff_datetime  \\\n",
       "count                       15145                       15145   \n",
       "mean   2022-05-08 02:16:15.216374  2022-05-08 02:34:11.021525   \n",
       "min           2020-01-01 01:16:17         2020-01-01 01:42:30   \n",
       "25%           2021-03-05 07:53:11         2021-03-05 08:16:01   \n",
       "50%           2022-05-09 23:03:02         2022-05-09 23:16:07   \n",
       "75%           2023-07-08 10:25:05         2023-07-08 10:36:17   \n",
       "max           2024-08-31 21:42:07         2024-08-31 22:39:49   \n",
       "std                           NaN                         NaN   \n",
       "\n",
       "       pick_up_location  drop_off_location    trip_miles     sales_tax  \\\n",
       "count      15145.000000       15145.000000  15145.000000  15145.000000   \n",
       "mean         138.076527         137.171476      4.421297      1.896094   \n",
       "min            3.000000           1.000000      0.000000      0.000000   \n",
       "25%           74.000000          74.000000      1.540000      0.920000   \n",
       "50%          140.000000         138.000000      2.840000      1.460000   \n",
       "75%          211.000000         208.000000      5.610000      2.370000   \n",
       "max          263.000000         263.000000     34.270000     18.420000   \n",
       "std           75.458304          75.408914      4.325343      1.448003   \n",
       "\n",
       "       congestion_surcharge   airport_fee          tips    driver_pay  \\\n",
       "count          15145.000000  15145.000000  15145.000000  15145.000000   \n",
       "mean               1.063982      0.132965      0.823195     17.004668   \n",
       "min                0.000000      0.000000      0.000000      0.000000   \n",
       "25%                0.000000      0.000000      0.000000      8.260000   \n",
       "50%                0.000000      0.000000      0.000000     13.290000   \n",
       "75%                2.750000      0.000000      0.000000     21.710000   \n",
       "max                2.750000      5.000000     46.110000    131.780000   \n",
       "std                1.334295      0.560936      2.469842     12.397572   \n",
       "\n",
       "       base_passenger_fare         tolls  trip_duration   pick_up_lat  \\\n",
       "count         15145.000000  15145.000000   15145.000000  15145.000000   \n",
       "mean             21.129109      0.654491    1075.805150     40.729596   \n",
       "min             -15.910000      0.000000       1.000000      0.000000   \n",
       "25%              10.510000      0.000000     557.000000     40.690787   \n",
       "50%              16.600000      0.000000     885.000000     40.737699   \n",
       "75%              26.360000      0.000000    1381.000000     40.775965   \n",
       "max             211.340000     46.450000    8534.000000     40.899529   \n",
       "std              15.664609      2.533267     739.205502      0.577492   \n",
       "\n",
       "        pick_up_lon  drop_off_lat  drop_off_lon  \n",
       "count  15145.000000  15145.000000  15145.000000  \n",
       "mean     -73.920892     40.731798    -73.925946  \n",
       "min      -74.233534      0.000000    -74.233534  \n",
       "25%      -73.985156     40.690787    -73.984196  \n",
       "50%      -73.948789     40.738324    -73.948522  \n",
       "75%      -73.899735     40.775932    -73.899536  \n",
       "max        0.000000     40.899529      0.000000  \n",
       "std        1.042600      0.473222      0.852350  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a15cbb",
   "metadata": {},
   "source": [
    "### Processing Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0ec5370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_paths = [\n",
    "    '2020_weather.csv',\n",
    "    '2021_weather.csv',\n",
    "    '2022_weather.csv',\n",
    "    '2023_weather.csv',\n",
    "    '2024_weather.csv'\n",
    "]\n",
    "\n",
    "def get_all_weather_csvs(directory):\n",
    "    all_dataframes = []\n",
    "    for file_path in directory:\n",
    "        df = pd.read_csv(file_path)\n",
    "        all_dataframes.append(df)\n",
    "    combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "    \n",
    "    return combined_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "76e864ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11211\\AppData\\Local\\Temp\\ipykernel_6424\\3311353840.py:12: DtypeWarning: Columns (8,9,10,17,18,64,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\11211\\AppData\\Local\\Temp\\ipykernel_6424\\3311353840.py:12: DtypeWarning: Columns (9,10,41,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\11211\\AppData\\Local\\Temp\\ipykernel_6424\\3311353840.py:12: DtypeWarning: Columns (8,10,17,18,41,62,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\11211\\AppData\\Local\\Temp\\ipykernel_6424\\3311353840.py:12: DtypeWarning: Columns (10,13,15,20,41,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\11211\\AppData\\Local\\Temp\\ipykernel_6424\\3311353840.py:12: DtypeWarning: Columns (8,9,10,15,17,18,19,20,38,41,42,43,44,58,64,65,77,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hourlyprecipitation</th>\n",
       "      <th>hourlywindspeed</th>\n",
       "      <th>dailysnowfall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01T00:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01T01:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01T02:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01T03:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01T04:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56093</th>\n",
       "      <td>2024-10-22T14:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56094</th>\n",
       "      <td>2024-10-22T15:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56095</th>\n",
       "      <td>2024-10-22T16:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56096</th>\n",
       "      <td>2024-10-22T17:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56097</th>\n",
       "      <td>2024-10-22T18:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56098 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date  hourlyprecipitation  hourlywindspeed  \\\n",
       "0      2020-01-01T00:51:00                  0.0              8.0   \n",
       "1      2020-01-01T01:51:00                  0.0              8.0   \n",
       "2      2020-01-01T02:51:00                  0.0             14.0   \n",
       "3      2020-01-01T03:51:00                  0.0             11.0   \n",
       "4      2020-01-01T04:51:00                  0.0              6.0   \n",
       "...                    ...                  ...              ...   \n",
       "56093  2024-10-22T14:51:00                  NaN              3.0   \n",
       "56094  2024-10-22T15:51:00                  NaN              0.0   \n",
       "56095  2024-10-22T16:51:00                  NaN              0.0   \n",
       "56096  2024-10-22T17:51:00                  NaN              0.0   \n",
       "56097  2024-10-22T18:51:00                  NaN              NaN   \n",
       "\n",
       "       dailysnowfall  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "2                NaN  \n",
       "3                NaN  \n",
       "4                NaN  \n",
       "...              ...  \n",
       "56093            NaN  \n",
       "56094            NaN  \n",
       "56095            NaN  \n",
       "56096            NaN  \n",
       "56097            NaN  \n",
       "\n",
       "[56098 rows x 4 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_paths = [\n",
    "    '2020_weather.csv',\n",
    "    '2021_weather.csv',\n",
    "    '2022_weather.csv',\n",
    "    '2023_weather.csv',\n",
    "    '2024_weather.csv'\n",
    "]\n",
    "def clean_month_weather_data_hourly(weather_paths):\n",
    "    '''\n",
    "    This function does the follows:\n",
    "        1. call get_all_weather_csvs(weather_paths) to obtain a big df\n",
    "        2. remove all columns other than 'DATE', 'HourlyPrecipitation', 'HourlyWindSpeed'\n",
    "        3. convert all input of 'HourlyPrecipitation', 'HourlyWindSpeed' into numeric values we use errors='coerce' here\n",
    "            because we have \"T\" as trace amount, we will record it as 0 here\n",
    "    '''\n",
    "    weather_df_hours = get_all_weather_csvs(weather_paths)\n",
    "    relevant_columns = ['DATE', 'HourlyPrecipitation', 'HourlyWindSpeed','DailySnowfall']\n",
    "    weather_df_hours = weather_df_hours[relevant_columns]\n",
    "    \n",
    "    weather_df_hours['HourlyPrecipitation'] = pd.to_numeric(weather_df_hours['HourlyPrecipitation'], errors='coerce')\n",
    "    weather_df_hours['HourlyWindSpeed'] = pd.to_numeric(weather_df_hours['HourlyWindSpeed'], errors='coerce')\n",
    "    weather_df_hours['DailySnowfall'] = pd.to_numeric(weather_df_hours['DailySnowfall'], errors='coerce')\n",
    "    weather_df_hours.columns = (\n",
    "        weather_df_hours.columns\n",
    "        .str.strip()               # Remove leading/trailing spaces\n",
    "        .str.lower()               # Convert to lowercase\n",
    "        .str.replace(' ', '_')     # Replace spaces with underscores\n",
    "        .str.replace(r'\\W+', '_')  # Replace non-word characters with underscores\n",
    "    )\n",
    "    return weather_df_hours\n",
    "\n",
    "x = clean_month_weather_data_hourly(weather_paths)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0687581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_daily(hourly_data):\n",
    "    \"\"\"\n",
    "    This function does the follows:\n",
    "    1. change all column values of Date into datetime\n",
    "    2. all values are numeric since it is gathered by hourly_data using previous hourly clean function\n",
    "    3. merge all rows in the same day and use average of precip and windspeed as new value, if such value is NaN, it will not be covered in denom\n",
    "        i.e. if we have 24 NaN the avg is NaN, if we have 23 NaN and a 1, the avg is 1\n",
    "    \"\"\"\n",
    "    daily_records = []\n",
    "    \n",
    "    hourly_data['date'] = pd.to_datetime(hourly_data['date'])\n",
    "    \n",
    "\n",
    "    for date, group in hourly_data.groupby(hourly_data['date'].dt.date):\n",
    "        avg_precipitation = group['hourlyprecipitation'].mean() if group['hourlyprecipitation'].notna().sum() >= 0 else float('nan')\n",
    "        avg_wind_speed = group['hourlywindspeed'].mean() if group['hourlywindspeed'].notna().sum() >= 0 else float('nan')\n",
    "        total_snowfall = (\n",
    "            group['dailysnowfall'].sum() if 'dailysnowfall' in group.columns and group['dailysnowfall'].notna().sum() >= 0 else float('nan')\n",
    "        )\n",
    "        daily_records.append({\n",
    "            'date': date,\n",
    "            'average_precipitation': avg_precipitation,\n",
    "            'average_wind_speed': avg_wind_speed,\n",
    "            'total_snowfall':total_snowfall\n",
    "        })\n",
    "\n",
    "    daily_data = pd.DataFrame(daily_records)\n",
    "    daily_data.columns = (\n",
    "        daily_data.columns\n",
    "        .str.strip()               # Remove leading/trailing spaces\n",
    "        .str.lower()               # Convert to lowercase\n",
    "        .str.replace(' ', '_')     # Replace spaces with underscores\n",
    "        .str.replace(r'\\W+', '_')  # Replace non-word characters with underscores\n",
    "    )\n",
    "    return daily_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "049dd736-9ec9-4b46-9ac5-ca4653960ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_weather_data():\n",
    "    weather_paths = [\n",
    "    '2020_weather.csv',\n",
    "    '2021_weather.csv',\n",
    "    '2022_weather.csv',\n",
    "    '2023_weather.csv',\n",
    "    '2024_weather.csv']\n",
    "    weather_df= get_all_weather_csvs(weather_paths)\n",
    "    weather_df_hours = clean_month_weather_data_hourly(weather_paths)\n",
    "    weather_df_days = clean_month_weather_data_daily(weather_df_hours)\n",
    "    return weather_df_hours, weather_df_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3ef8945d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef load_and_clean_weather_data():\\n    weather_csv_files = get_all_weather_csvs(WEATHER_CSV_DIR)\\n    \\n    hourly_dataframes = []\\n    daily_dataframes = []\\n        \\n    for csv_file in weather_csv_files:\\n        hourly_dataframe = clean_month_weather_data_hourly(csv_file)\\n        daily_dataframe = clean_month_weather_data_daily(csv_file)\\n        hourly_dataframes.append(hourly_dataframe)\\n        daily_dataframes.append(daily_dataframe)\\n        \\n    # create two dataframes with hourly & daily data from every month\\n    hourly_data = pd.concat(hourly_dataframes)\\n    daily_data = pd.concat(daily_dataframes)\\n    \\n    return hourly_data, daily_data\\n'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def load_and_clean_weather_data():\n",
    "    weather_csv_files = get_all_weather_csvs(WEATHER_CSV_DIR)\n",
    "    \n",
    "    hourly_dataframes = []\n",
    "    daily_dataframes = []\n",
    "        \n",
    "    for csv_file in weather_csv_files:\n",
    "        hourly_dataframe = clean_month_weather_data_hourly(csv_file)\n",
    "        daily_dataframe = clean_month_weather_data_daily(csv_file)\n",
    "        hourly_dataframes.append(hourly_dataframe)\n",
    "        daily_dataframes.append(daily_dataframe)\n",
    "        \n",
    "    # create two dataframes with hourly & daily data from every month\n",
    "    hourly_data = pd.concat(hourly_dataframes)\n",
    "    daily_data = pd.concat(daily_dataframes)\n",
    "    \n",
    "    return hourly_data, daily_data\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f7cd53a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11211\\AppData\\Local\\Temp\\ipykernel_6424\\3311353840.py:12: DtypeWarning: Columns (8,9,10,17,18,64,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\11211\\AppData\\Local\\Temp\\ipykernel_6424\\3311353840.py:12: DtypeWarning: Columns (9,10,41,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\11211\\AppData\\Local\\Temp\\ipykernel_6424\\3311353840.py:12: DtypeWarning: Columns (8,10,17,18,41,62,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\11211\\AppData\\Local\\Temp\\ipykernel_6424\\3311353840.py:12: DtypeWarning: Columns (10,13,15,20,41,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\11211\\AppData\\Local\\Temp\\ipykernel_6424\\3311353840.py:12: DtypeWarning: Columns (8,9,10,15,17,18,19,20,38,41,42,43,44,58,64,65,77,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\11211\\AppData\\Local\\Temp\\ipykernel_6424\\3311353840.py:12: DtypeWarning: Columns (8,9,10,17,18,64,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\11211\\AppData\\Local\\Temp\\ipykernel_6424\\3311353840.py:12: DtypeWarning: Columns (9,10,41,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\11211\\AppData\\Local\\Temp\\ipykernel_6424\\3311353840.py:12: DtypeWarning: Columns (8,10,17,18,41,62,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\11211\\AppData\\Local\\Temp\\ipykernel_6424\\3311353840.py:12: DtypeWarning: Columns (10,13,15,20,41,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\11211\\AppData\\Local\\Temp\\ipykernel_6424\\3311353840.py:12: DtypeWarning: Columns (8,9,10,15,17,18,19,20,38,41,42,43,44,58,64,65,77,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "hourly_weather, daily_weather = load_and_clean_weather_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "48216557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hourlyprecipitation</th>\n",
       "      <th>hourlywindspeed</th>\n",
       "      <th>dailysnowfall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01 00:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01 01:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01 02:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01 03:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01 04:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  hourlyprecipitation  hourlywindspeed  dailysnowfall\n",
       "0 2020-01-01 00:51:00                  0.0              8.0            NaN\n",
       "1 2020-01-01 01:51:00                  0.0              8.0            NaN\n",
       "2 2020-01-01 02:51:00                  0.0             14.0            NaN\n",
       "3 2020-01-01 03:51:00                  0.0             11.0            NaN\n",
       "4 2020-01-01 04:51:00                  0.0              6.0            NaN"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "935261b7-ae23-427c-97ff-ea31aa4e44c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56098 entries, 0 to 56097\n",
      "Data columns (total 4 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   date                 56098 non-null  datetime64[ns]\n",
      " 1   hourlyprecipitation  43765 non-null  float64       \n",
      " 2   hourlywindspeed      49660 non-null  float64       \n",
      " 3   dailysnowfall        1690 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(3)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "hourly_weather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a7dcb502-d1d1-447d-aa68-11bff0dc53b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hourlyprecipitation</th>\n",
       "      <th>hourlywindspeed</th>\n",
       "      <th>dailysnowfall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>56098</td>\n",
       "      <td>43765.000000</td>\n",
       "      <td>49660.000000</td>\n",
       "      <td>1690.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2022-05-29 21:14:19.618881024</td>\n",
       "      <td>0.013187</td>\n",
       "      <td>5.125453</td>\n",
       "      <td>0.040592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2020-01-01 00:51:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2021-03-18 19:01:45</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022-05-28 01:21:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023-08-15 05:39:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024-10-22 18:51:00</td>\n",
       "      <td>3.470000</td>\n",
       "      <td>2237.000000</td>\n",
       "      <td>14.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.063137</td>\n",
       "      <td>14.653212</td>\n",
       "      <td>0.502802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                date  hourlyprecipitation  hourlywindspeed  \\\n",
       "count                          56098         43765.000000     49660.000000   \n",
       "mean   2022-05-29 21:14:19.618881024             0.013187         5.125453   \n",
       "min              2020-01-01 00:51:00             0.000000         0.000000   \n",
       "25%              2021-03-18 19:01:45             0.000000         3.000000   \n",
       "50%              2022-05-28 01:21:00             0.000000         5.000000   \n",
       "75%              2023-08-15 05:39:00             0.000000         7.000000   \n",
       "max              2024-10-22 18:51:00             3.470000      2237.000000   \n",
       "std                              NaN             0.063137        14.653212   \n",
       "\n",
       "       dailysnowfall  \n",
       "count    1690.000000  \n",
       "mean        0.040592  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max        14.800000  \n",
       "std         0.502802  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_weather.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4cb386ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>average_precipitation</th>\n",
       "      <th>average_wind_speed</th>\n",
       "      <th>total_snowfall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.458333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>0.008077</td>\n",
       "      <td>3.305556</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>0.017941</td>\n",
       "      <td>3.421053</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>2024-10-18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>2024-10-19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.217391</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>2024-10-20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>2024-10-21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>2024-10-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1757 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  average_precipitation  average_wind_speed  total_snowfall\n",
       "0     2020-01-01               0.000000            8.458333             0.0\n",
       "1     2020-01-02               0.000000            5.500000             0.0\n",
       "2     2020-01-03               0.008077            3.305556             0.0\n",
       "3     2020-01-04               0.017941            3.421053             0.0\n",
       "4     2020-01-05               0.000000           11.333333             0.0\n",
       "...          ...                    ...                 ...             ...\n",
       "1752  2024-10-18               0.000000            4.250000             0.0\n",
       "1753  2024-10-19               0.000000            1.217391             0.0\n",
       "1754  2024-10-20               0.000000            1.416667             0.0\n",
       "1755  2024-10-21               0.000000            2.500000             0.0\n",
       "1756  2024-10-22                    NaN            1.750000             0.0\n",
       "\n",
       "[1757 rows x 4 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f090eb94-a5b0-4d93-bf82-a596d2521b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1757 entries, 0 to 1756\n",
      "Data columns (total 4 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   date                   1757 non-null   object \n",
      " 1   average_precipitation  1754 non-null   float64\n",
      " 2   average_wind_speed     1704 non-null   float64\n",
      " 3   total_snowfall         1757 non-null   float64\n",
      "dtypes: float64(3), object(1)\n",
      "memory usage: 55.0+ KB\n"
     ]
    }
   ],
   "source": [
    "daily_weather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8c074aa3-a5f2-4586-8748-411e1e6c11da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_precipitation</th>\n",
       "      <th>average_wind_speed</th>\n",
       "      <th>total_snowfall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1754.000000</td>\n",
       "      <td>1704.000000</td>\n",
       "      <td>1757.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.009717</td>\n",
       "      <td>5.089830</td>\n",
       "      <td>0.039044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.026218</td>\n",
       "      <td>3.928107</td>\n",
       "      <td>0.493178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.620635</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.004319</td>\n",
       "      <td>6.394830</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.355333</td>\n",
       "      <td>108.227273</td>\n",
       "      <td>14.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       average_precipitation  average_wind_speed  total_snowfall\n",
       "count            1754.000000         1704.000000     1757.000000\n",
       "mean                0.009717            5.089830        0.039044\n",
       "std                 0.026218            3.928107        0.493178\n",
       "min                 0.000000            0.447368        0.000000\n",
       "25%                 0.000000            3.166667        0.000000\n",
       "50%                 0.000000            4.620635        0.000000\n",
       "75%                 0.004319            6.394830        0.000000\n",
       "max                 0.355333          108.227273       14.800000"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd101f11",
   "metadata": {},
   "source": [
    "## Part 2: Storing Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f3529cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13ede01-d7a0-49c3-a406-ad5fb65e6d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "d2bea0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using SQL (as opposed to SQLAlchemy), define the commands \n",
    "# to create your 4 tables/dataframes\n",
    "HOURLY_WEATHER_SCHEMA = \"\"\"\n",
    "DROP TABLE IF EXISTS hourly_weather;\n",
    "CREATE TABLE IF NOT EXISTS hourly_weather (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    date DATETIME NOT NULL,\n",
    "    hourlyprecipitation FLOAT,\n",
    "    hourlywindspeed FLOAT,\n",
    "    dailysnowfall FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "DAILY_WEATHER_SCHEMA = \"\"\"\n",
    "DROP TABLE IF EXISTS daily_weather;\n",
    "CREATE TABLE IF NOT EXISTS daily_weather (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    date DATE NOT NULL,\n",
    "    average_precipitation FLOAT,\n",
    "    average_wind_speed FLOAT,\n",
    "    total_snowfall FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "TAXI_TRIPS_SCHEMA = \"\"\"\n",
    "DROP TABLE IF EXISTS taxi_trips;\n",
    "CREATE TABLE IF NOT EXISTS taxi_trips (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    pickup_time DATETIME NOT NULL,\n",
    "    dropoff_time DATETIME NOT NULL,\n",
    "    trip_distance FLOAT,\n",
    "    pick_up_location INT,\n",
    "    drop_off_location INT,\n",
    "    fare_amount FLOAT,\n",
    "    extra FLOAT,\n",
    "    mta_tax FLOAT,\n",
    "    tip_amount FLOAT,\n",
    "    tolls_amount FLOAT,\n",
    "    improvement_surcharge FLOAT,\n",
    "    total_amount FLOAT,\n",
    "    congestion_surcharge FLOAT,\n",
    "    airport_fee FLOAT,\n",
    "    pick_up_lat FLOAT,\n",
    "    pick_up_lon FLOAT,\n",
    "    drop_off_lat FLOAT,\n",
    "    drop_off_lon FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "UBER_TRIPS_SCHEMA = \"\"\"\n",
    "DROP TABLE IF EXISTS uber_trips;\n",
    "CREATE TABLE IF NOT EXISTS uber_trips (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    uber_license_num STRING,\n",
    "    pickup_datetime DATETIME NOT NULL,\n",
    "    dropoff_datetime DATETIME NOT NULL,\n",
    "    pick_up_location INT,\n",
    "    drop_off_location INT,\n",
    "    trip_miles FLOAT,\n",
    "    sales_tax FLOAT,\n",
    "    congestion_surcharge FLOAT,\n",
    "    airport_fee FLOAT,\n",
    "    tips FLOAT,\n",
    "    driver_pay FLOAT,\n",
    "    base_passenger_fare FLOAT,\n",
    "    tolls FLOAT,\n",
    "    trip_duration FLOAT,\n",
    "    pick_up_lat FLOAT,\n",
    "    pick_up_lon FLOAT,\n",
    "    drop_off_lat FLOAT,\n",
    "    drop_off_lon FLOAT\n",
    "  \n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "5f41e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open(DATABASE_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(HOURLY_WEATHER_SCHEMA)\n",
    "    f.write(DAILY_WEATHER_SCHEMA)\n",
    "    f.write(TAXI_TRIPS_SCHEMA)\n",
    "    f.write(UBER_TRIPS_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "6b54a568-0db8-4f26-8743-25ab65376118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_1.db\n"
     ]
    }
   ],
   "source": [
    "print(engine.url.database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "97c538ac-4a83-44cc-8ba6-3f337af7993c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Databse created successfully.\n"
     ]
    }
   ],
   "source": [
    "# create tables with the schema files\n",
    "with engine.connect() as connection:\n",
    "    with open(DATABASE_SCHEMA_FILE, \"r\") as schema_file:\n",
    "        schema_script = schema_file.read()\n",
    "        statements = schema_script.split(\";\")  \n",
    "        for statement in statements:\n",
    "            statement = statement.strip()\n",
    "            #Ignore empty statement\n",
    "            if statement: \n",
    "                connection.execute(text(statement))\n",
    "\n",
    "print(\"Databse created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c122964f",
   "metadata": {},
   "source": [
    "### Add Data to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "2d0e8b96-6a04-4883-a7d1-8807d9e3a546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writes the dataframes to the SQL tables\n",
    "def write_dataframes_to_table(table_to_df_dict, engine):\n",
    "    with engine.connect() as connection:  \n",
    "        for table_name, dataframe in table_to_df_dict.items():\n",
    "            print(f\"Dataframe wrote to table: {table_name}\")\n",
    "            dataframe.to_sql(table_name, con=connection, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "45d6c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_table_name_to_dataframe = {\n",
    "    \"taxi_trips\": taxi_data,\n",
    "    \"uber_trips\": uber_data,\n",
    "    \"hourly_weather\": hourly_weather,\n",
    "    \"daily_weather\": daily_weather\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "74004f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe wrote to table: taxi_trips\n",
      "Dataframe wrote to table: uber_trips\n",
      "Dataframe wrote to table: hourly_weather\n",
      "Dataframe wrote to table: daily_weather\n"
     ]
    }
   ],
   "source": [
    "write_dataframes_to_table(map_table_name_to_dataframe,engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "23e3b321-fdc2-44e8-814b-f757b7367849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_time</th>\n",
       "      <th>dropoff_time</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pick_up_location</th>\n",
       "      <th>drop_off_location</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>pick_up_lat</th>\n",
       "      <th>pick_up_lon</th>\n",
       "      <th>drop_off_lat</th>\n",
       "      <th>drop_off_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1932305</th>\n",
       "      <td>2024-01-22 19:05:09</td>\n",
       "      <td>2024-01-22 19:23:44</td>\n",
       "      <td>6.66</td>\n",
       "      <td>233</td>\n",
       "      <td>231</td>\n",
       "      <td>28.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.94</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.749914</td>\n",
       "      <td>-73.970443</td>\n",
       "      <td>40.717773</td>\n",
       "      <td>-74.007880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157302</th>\n",
       "      <td>2024-01-14 09:06:21</td>\n",
       "      <td>2024-01-14 09:18:33</td>\n",
       "      <td>4.49</td>\n",
       "      <td>140</td>\n",
       "      <td>166</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.40</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.765484</td>\n",
       "      <td>-73.954739</td>\n",
       "      <td>40.809457</td>\n",
       "      <td>-73.961764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291875</th>\n",
       "      <td>2024-01-26 13:53:49</td>\n",
       "      <td>2024-01-26 14:02:51</td>\n",
       "      <td>1.07</td>\n",
       "      <td>230</td>\n",
       "      <td>246</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.60</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.759818</td>\n",
       "      <td>-73.984196</td>\n",
       "      <td>40.753309</td>\n",
       "      <td>-74.004015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694766</th>\n",
       "      <td>2024-01-20 01:09:56</td>\n",
       "      <td>2024-01-20 01:15:24</td>\n",
       "      <td>1.27</td>\n",
       "      <td>68</td>\n",
       "      <td>50</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.90</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.748428</td>\n",
       "      <td>-73.999917</td>\n",
       "      <td>40.766238</td>\n",
       "      <td>-73.995135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509429</th>\n",
       "      <td>2024-01-06 22:10:22</td>\n",
       "      <td>2024-01-06 22:29:31</td>\n",
       "      <td>3.82</td>\n",
       "      <td>90</td>\n",
       "      <td>239</td>\n",
       "      <td>21.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.20</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.742279</td>\n",
       "      <td>-73.996971</td>\n",
       "      <td>40.783961</td>\n",
       "      <td>-73.978632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642552</th>\n",
       "      <td>2020-12-14 09:16:35</td>\n",
       "      <td>2020-12-14 09:35:13</td>\n",
       "      <td>2.82</td>\n",
       "      <td>24</td>\n",
       "      <td>163</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>21.36</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.801970</td>\n",
       "      <td>-73.965480</td>\n",
       "      <td>40.764421</td>\n",
       "      <td>-73.977569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504955</th>\n",
       "      <td>2020-12-11 10:09:31</td>\n",
       "      <td>2020-12-11 10:13:55</td>\n",
       "      <td>0.30</td>\n",
       "      <td>141</td>\n",
       "      <td>140</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.35</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.766948</td>\n",
       "      <td>-73.959635</td>\n",
       "      <td>40.765484</td>\n",
       "      <td>-73.954739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311675</th>\n",
       "      <td>2020-12-07 14:52:48</td>\n",
       "      <td>2020-12-07 14:58:31</td>\n",
       "      <td>1.05</td>\n",
       "      <td>107</td>\n",
       "      <td>170</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.16</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.736824</td>\n",
       "      <td>-73.984052</td>\n",
       "      <td>40.747746</td>\n",
       "      <td>-73.978492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805620</th>\n",
       "      <td>2020-12-17 19:59:42</td>\n",
       "      <td>2020-12-17 20:02:27</td>\n",
       "      <td>0.62</td>\n",
       "      <td>239</td>\n",
       "      <td>236</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.38</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.783961</td>\n",
       "      <td>-73.978632</td>\n",
       "      <td>40.780436</td>\n",
       "      <td>-73.957012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158626</th>\n",
       "      <td>2020-12-04 07:57:45</td>\n",
       "      <td>2020-12-04 08:07:00</td>\n",
       "      <td>4.60</td>\n",
       "      <td>87</td>\n",
       "      <td>162</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.706808</td>\n",
       "      <td>-74.007496</td>\n",
       "      <td>40.756688</td>\n",
       "      <td>-73.972356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19820 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                pickup_time        dropoff_time  trip_distance  \\\n",
       "1932305 2024-01-22 19:05:09 2024-01-22 19:23:44           6.66   \n",
       "1157302 2024-01-14 09:06:21 2024-01-14 09:18:33           4.49   \n",
       "2291875 2024-01-26 13:53:49 2024-01-26 14:02:51           1.07   \n",
       "1694766 2024-01-20 01:09:56 2024-01-20 01:15:24           1.27   \n",
       "509429  2024-01-06 22:10:22 2024-01-06 22:29:31           3.82   \n",
       "...                     ...                 ...            ...   \n",
       "642552  2020-12-14 09:16:35 2020-12-14 09:35:13           2.82   \n",
       "504955  2020-12-11 10:09:31 2020-12-11 10:13:55           0.30   \n",
       "311675  2020-12-07 14:52:48 2020-12-07 14:58:31           1.05   \n",
       "805620  2020-12-17 19:59:42 2020-12-17 20:02:27           0.62   \n",
       "158626  2020-12-04 07:57:45 2020-12-04 08:07:00           4.60   \n",
       "\n",
       "         pick_up_location  drop_off_location  fare_amount  extra  mta_tax  \\\n",
       "1932305               233                231         28.9    2.5      0.5   \n",
       "1157302               140                166         20.5    0.0      0.5   \n",
       "2291875               230                246          9.3    0.0      0.5   \n",
       "1694766                68                 50          7.9    1.0      0.5   \n",
       "509429                 90                239         21.2    1.0      0.5   \n",
       "...                   ...                ...          ...    ...      ...   \n",
       "642552                 24                163         14.5    0.0      0.5   \n",
       "504955                141                140          4.5    2.5      0.5   \n",
       "311675                107                170          6.0    0.0      0.5   \n",
       "805620                239                236          4.5    0.5      0.5   \n",
       "158626                 87                162         14.0    2.5      0.5   \n",
       "\n",
       "         tip_amount  tolls_amount  improvement_surcharge  total_amount  \\\n",
       "1932305        3.54           0.0                    1.0         38.94   \n",
       "1157302        4.90           0.0                    1.0         29.40   \n",
       "2291875        1.30           0.0                    1.0         14.60   \n",
       "1694766        0.00           0.0                    1.0         12.90   \n",
       "509429         0.00           0.0                    1.0         26.20   \n",
       "...             ...           ...                    ...           ...   \n",
       "642552         3.56           0.0                    0.3         21.36   \n",
       "504955         1.55           0.0                    0.3          9.35   \n",
       "311675         1.86           0.0                    0.3         11.16   \n",
       "805620         2.08           0.0                    0.3         10.38   \n",
       "158626         3.00           0.0                    0.3         20.30   \n",
       "\n",
       "         congestion_surcharge  airport_fee  pick_up_lat  pick_up_lon  \\\n",
       "1932305                   2.5          0.0    40.749914   -73.970443   \n",
       "1157302                   2.5          0.0    40.765484   -73.954739   \n",
       "2291875                   2.5          0.0    40.759818   -73.984196   \n",
       "1694766                   2.5          0.0    40.748428   -73.999917   \n",
       "509429                    2.5          0.0    40.742279   -73.996971   \n",
       "...                       ...          ...          ...          ...   \n",
       "642552                    2.5          0.0    40.801970   -73.965480   \n",
       "504955                    2.5          0.0    40.766948   -73.959635   \n",
       "311675                    2.5          0.0    40.736824   -73.984052   \n",
       "805620                    2.5          0.0    40.783961   -73.978632   \n",
       "158626                    2.5          0.0    40.706808   -74.007496   \n",
       "\n",
       "         drop_off_lat  drop_off_lon  \n",
       "1932305     40.717773    -74.007880  \n",
       "1157302     40.809457    -73.961764  \n",
       "2291875     40.753309    -74.004015  \n",
       "1694766     40.766238    -73.995135  \n",
       "509429      40.783961    -73.978632  \n",
       "...               ...           ...  \n",
       "642552      40.764421    -73.977569  \n",
       "504955      40.765484    -73.954739  \n",
       "311675      40.747746    -73.978492  \n",
       "805620      40.780436    -73.957012  \n",
       "158626      40.756688    -73.972356  \n",
       "\n",
       "[19820 rows x 18 columns]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "db82c441-f699-47e6-857f-faa238c12062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uber_license_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pick_up_location</th>\n",
       "      <th>drop_off_location</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>sales_tax</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>tips</th>\n",
       "      <th>driver_pay</th>\n",
       "      <th>base_passenger_fare</th>\n",
       "      <th>tolls</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>pick_up_lat</th>\n",
       "      <th>pick_up_lon</th>\n",
       "      <th>drop_off_lat</th>\n",
       "      <th>drop_off_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5015332</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2024-01-09 17:03:05</td>\n",
       "      <td>2024-01-09 17:18:47</td>\n",
       "      <td>112</td>\n",
       "      <td>7</td>\n",
       "      <td>2.19</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.88</td>\n",
       "      <td>13.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>942.0</td>\n",
       "      <td>40.729506</td>\n",
       "      <td>-73.949540</td>\n",
       "      <td>40.761493</td>\n",
       "      <td>-73.919694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11789217</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2024-01-19 23:35:31</td>\n",
       "      <td>2024-01-20 00:00:13</td>\n",
       "      <td>164</td>\n",
       "      <td>152</td>\n",
       "      <td>7.33</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23.56</td>\n",
       "      <td>23.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1482.0</td>\n",
       "      <td>40.748575</td>\n",
       "      <td>-73.985156</td>\n",
       "      <td>40.817975</td>\n",
       "      <td>-73.953782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8838746</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2024-01-15 15:04:02</td>\n",
       "      <td>2024-01-15 15:13:23</td>\n",
       "      <td>76</td>\n",
       "      <td>63</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.18</td>\n",
       "      <td>9.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>561.0</td>\n",
       "      <td>40.660935</td>\n",
       "      <td>-73.876821</td>\n",
       "      <td>40.683840</td>\n",
       "      <td>-73.878173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2847174</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2024-01-06 00:13:10</td>\n",
       "      <td>2024-01-06 00:46:36</td>\n",
       "      <td>205</td>\n",
       "      <td>159</td>\n",
       "      <td>18.66</td>\n",
       "      <td>4.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44.19</td>\n",
       "      <td>46.77</td>\n",
       "      <td>6.94</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>40.691201</td>\n",
       "      <td>-73.763146</td>\n",
       "      <td>40.818260</td>\n",
       "      <td>-73.912849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4215586</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2024-01-08 08:12:38</td>\n",
       "      <td>2024-01-08 08:55:49</td>\n",
       "      <td>66</td>\n",
       "      <td>132</td>\n",
       "      <td>18.24</td>\n",
       "      <td>6.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>48.32</td>\n",
       "      <td>75.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2591.0</td>\n",
       "      <td>40.702259</td>\n",
       "      <td>-73.985702</td>\n",
       "      <td>40.646985</td>\n",
       "      <td>-73.786533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7208488</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2020-12-19 20:31:49</td>\n",
       "      <td>2020-12-19 20:46:36</td>\n",
       "      <td>148</td>\n",
       "      <td>229</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1.19</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>10.62</td>\n",
       "      <td>13.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>887.0</td>\n",
       "      <td>40.718938</td>\n",
       "      <td>-73.990896</td>\n",
       "      <td>40.756729</td>\n",
       "      <td>-73.965146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3494705</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2020-12-10 13:07:50</td>\n",
       "      <td>2020-12-10 13:36:46</td>\n",
       "      <td>39</td>\n",
       "      <td>188</td>\n",
       "      <td>4.84</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.87</td>\n",
       "      <td>20.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1736.0</td>\n",
       "      <td>40.638037</td>\n",
       "      <td>-73.899735</td>\n",
       "      <td>40.658744</td>\n",
       "      <td>-73.947442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3786293</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2020-12-11 08:43:22</td>\n",
       "      <td>2020-12-11 08:56:43</td>\n",
       "      <td>169</td>\n",
       "      <td>159</td>\n",
       "      <td>3.11</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.14</td>\n",
       "      <td>11.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>801.0</td>\n",
       "      <td>40.849058</td>\n",
       "      <td>-73.905122</td>\n",
       "      <td>40.818260</td>\n",
       "      <td>-73.912849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73764</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2020-12-01 09:46:38</td>\n",
       "      <td>2020-12-01 10:03:33</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>2.16</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.82</td>\n",
       "      <td>10.88</td>\n",
       "      <td>11.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>40.691507</td>\n",
       "      <td>-73.949905</td>\n",
       "      <td>40.685634</td>\n",
       "      <td>-73.986114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2648156</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2020-12-08 07:21:45</td>\n",
       "      <td>2020-12-08 07:55:42</td>\n",
       "      <td>241</td>\n",
       "      <td>246</td>\n",
       "      <td>11.67</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.92</td>\n",
       "      <td>37.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2037.0</td>\n",
       "      <td>40.876512</td>\n",
       "      <td>-73.895620</td>\n",
       "      <td>40.753309</td>\n",
       "      <td>-74.004015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15145 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         uber_license_num     pickup_datetime    dropoff_datetime  \\\n",
       "5015332            HV0003 2024-01-09 17:03:05 2024-01-09 17:18:47   \n",
       "11789217           HV0003 2024-01-19 23:35:31 2024-01-20 00:00:13   \n",
       "8838746            HV0003 2024-01-15 15:04:02 2024-01-15 15:13:23   \n",
       "2847174            HV0003 2024-01-06 00:13:10 2024-01-06 00:46:36   \n",
       "4215586            HV0003 2024-01-08 08:12:38 2024-01-08 08:55:49   \n",
       "...                   ...                 ...                 ...   \n",
       "7208488            HV0003 2020-12-19 20:31:49 2020-12-19 20:46:36   \n",
       "3494705            HV0003 2020-12-10 13:07:50 2020-12-10 13:36:46   \n",
       "3786293            HV0003 2020-12-11 08:43:22 2020-12-11 08:56:43   \n",
       "73764              HV0003 2020-12-01 09:46:38 2020-12-01 10:03:33   \n",
       "2648156            HV0003 2020-12-08 07:21:45 2020-12-08 07:55:42   \n",
       "\n",
       "          pick_up_location  drop_off_location  trip_miles  sales_tax  \\\n",
       "5015332                112                  7        2.19       1.22   \n",
       "11789217               164                152        7.33       2.12   \n",
       "8838746                 76                 63        1.45       0.87   \n",
       "2847174                205                159       18.66       4.77   \n",
       "4215586                 66                132       18.24       6.92   \n",
       "...                    ...                ...         ...        ...   \n",
       "7208488                148                229        2.89       1.19   \n",
       "3494705                 39                188        4.84       1.85   \n",
       "3786293                169                159        3.11       1.00   \n",
       "73764                   17                 25        2.16       1.01   \n",
       "2648156                241                246       11.67       3.30   \n",
       "\n",
       "          congestion_surcharge  airport_fee  tips  driver_pay  \\\n",
       "5015332                   0.00          0.0  0.00        5.88   \n",
       "11789217                  2.75          0.0  0.00       23.56   \n",
       "8838746                   0.00          0.0  0.00        7.18   \n",
       "2847174                   0.00          0.0  0.00       44.19   \n",
       "4215586                   0.00          2.5  0.00       48.32   \n",
       "...                        ...          ...   ...         ...   \n",
       "7208488                   2.75          0.0  0.94       10.62   \n",
       "3494705                   0.00          0.0  0.00       19.87   \n",
       "3786293                   0.00          0.0  0.00       10.14   \n",
       "73764                     0.00          0.0  2.82       10.88   \n",
       "2648156                   2.75          0.0  0.00       29.92   \n",
       "\n",
       "          base_passenger_fare  tolls  trip_duration  pick_up_lat  pick_up_lon  \\\n",
       "5015332                 13.75   0.00          942.0    40.729506   -73.949540   \n",
       "11789217                23.85   0.00         1482.0    40.748575   -73.985156   \n",
       "8838746                  9.79   0.00          561.0    40.660935   -73.876821   \n",
       "2847174                 46.77   6.94         2006.0    40.691201   -73.763146   \n",
       "4215586                 75.43   0.00         2591.0    40.702259   -73.985702   \n",
       "...                       ...    ...            ...          ...          ...   \n",
       "7208488                 13.13   0.00          887.0    40.718938   -73.990896   \n",
       "3494705                 20.86   0.00         1736.0    40.638037   -73.899735   \n",
       "3786293                 11.26   0.00          801.0    40.849058   -73.905122   \n",
       "73764                   11.25   0.00         1015.0    40.691507   -73.949905   \n",
       "2648156                 37.20   0.00         2037.0    40.876512   -73.895620   \n",
       "\n",
       "          drop_off_lat  drop_off_lon  \n",
       "5015332      40.761493    -73.919694  \n",
       "11789217     40.817975    -73.953782  \n",
       "8838746      40.683840    -73.878173  \n",
       "2847174      40.818260    -73.912849  \n",
       "4215586      40.646985    -73.786533  \n",
       "...                ...           ...  \n",
       "7208488      40.756729    -73.965146  \n",
       "3494705      40.658744    -73.947442  \n",
       "3786293      40.818260    -73.912849  \n",
       "73764        40.685634    -73.986114  \n",
       "2648156      40.753309    -74.004015  \n",
       "\n",
       "[15145 rows x 18 columns]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "da58d1d1-8452-4c64-ac11-8676f31a5dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hourlyprecipitation</th>\n",
       "      <th>hourlywindspeed</th>\n",
       "      <th>dailysnowfall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01 00:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01 01:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01 02:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01 03:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01 04:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56093</th>\n",
       "      <td>2024-10-22 14:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56094</th>\n",
       "      <td>2024-10-22 15:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56095</th>\n",
       "      <td>2024-10-22 16:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56096</th>\n",
       "      <td>2024-10-22 17:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56097</th>\n",
       "      <td>2024-10-22 18:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56098 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date  hourlyprecipitation  hourlywindspeed  dailysnowfall\n",
       "0     2020-01-01 00:51:00                  0.0              8.0            NaN\n",
       "1     2020-01-01 01:51:00                  0.0              8.0            NaN\n",
       "2     2020-01-01 02:51:00                  0.0             14.0            NaN\n",
       "3     2020-01-01 03:51:00                  0.0             11.0            NaN\n",
       "4     2020-01-01 04:51:00                  0.0              6.0            NaN\n",
       "...                   ...                  ...              ...            ...\n",
       "56093 2024-10-22 14:51:00                  NaN              3.0            NaN\n",
       "56094 2024-10-22 15:51:00                  NaN              0.0            NaN\n",
       "56095 2024-10-22 16:51:00                  NaN              0.0            NaN\n",
       "56096 2024-10-22 17:51:00                  NaN              0.0            NaN\n",
       "56097 2024-10-22 18:51:00                  NaN              NaN            NaN\n",
       "\n",
       "[56098 rows x 4 columns]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "12a858c1-aada-414c-aa74-4b78b2f4730e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>average_precipitation</th>\n",
       "      <th>average_wind_speed</th>\n",
       "      <th>total_snowfall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.458333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>0.008077</td>\n",
       "      <td>3.305556</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>0.017941</td>\n",
       "      <td>3.421053</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>2024-10-18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>2024-10-19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.217391</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>2024-10-20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>2024-10-21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>2024-10-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1757 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  average_precipitation  average_wind_speed  total_snowfall\n",
       "0     2020-01-01               0.000000            8.458333             0.0\n",
       "1     2020-01-02               0.000000            5.500000             0.0\n",
       "2     2020-01-03               0.008077            3.305556             0.0\n",
       "3     2020-01-04               0.017941            3.421053             0.0\n",
       "4     2020-01-05               0.000000           11.333333             0.0\n",
       "...          ...                    ...                 ...             ...\n",
       "1752  2024-10-18               0.000000            4.250000             0.0\n",
       "1753  2024-10-19               0.000000            1.217391             0.0\n",
       "1754  2024-10-20               0.000000            1.416667             0.0\n",
       "1755  2024-10-21               0.000000            2.500000             0.0\n",
       "1756  2024-10-22                    NaN            1.750000             0.0\n",
       "\n",
       "[1757 rows x 4 columns]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6e33e",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "6a849e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to write the queries to file\n",
    "def write_query_to_file(query, outfile):\n",
    "    with open(outfile, 'w') as file:\n",
    "        file.write(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70a777",
   "metadata": {},
   "source": [
    "### Query 1\n",
    "#### Q: What is the most popular hour to take taxi?\n",
    "#### A: The most popular hour to take taxi is 18:00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "db871d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Query file to analysis the result of most popular hour\n",
    "QUERY_1_FILENAME = \"taxi_most_popular_hour.sql\"\n",
    "QUERY_1 = \"\"\"\n",
    "SELECT \n",
    "    STRFTIME('%H', pickup_time) AS hour_of_day,\n",
    "    COUNT(*) AS trip_count\n",
    "FROM \n",
    "    taxi_trips\n",
    "WHERE \n",
    "    pickup_time BETWEEN '2020-01-01' AND '2024-08-31'\n",
    "GROUP BY \n",
    "    hour_of_day\n",
    "ORDER BY \n",
    "    trip_count DESC;\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "c5275f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>trip_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>1419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>1338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>1326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>1288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19</td>\n",
       "      <td>1279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>1202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>1134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>1079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>1061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>22</td>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>09</td>\n",
       "      <td>914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21</td>\n",
       "      <td>904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>08</td>\n",
       "      <td>786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>23</td>\n",
       "      <td>677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>07</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00</td>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>01</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>06</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>02</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>03</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>05</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>04</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hour_of_day  trip_count\n",
       "0           18        1419\n",
       "1           16        1357\n",
       "2           17        1338\n",
       "3           15        1326\n",
       "4           14        1288\n",
       "5           19        1279\n",
       "6           12        1202\n",
       "7           13        1134\n",
       "8           11        1079\n",
       "9           20        1061\n",
       "10          10         940\n",
       "11          22         915\n",
       "12          09         914\n",
       "13          21         904\n",
       "14          08         786\n",
       "15          23         677\n",
       "16          07         591\n",
       "17          00         448\n",
       "18          01         314\n",
       "19          06         309\n",
       "20          02         193\n",
       "21          03         136\n",
       "22          05         127\n",
       "23          04          76"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# execute query either via sqlalchemy\n",
    "with engine.connect() as con:\n",
    "    results = con.execute(db.text(QUERY_1)).fetchall()\n",
    "results\n",
    "# or via pandas\n",
    "pd.read_sql(QUERY_1, con=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "a2ef04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_1, f\"{QUERY_DIRECTORY}/{QUERY_1_FILENAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34457f91-63dd-4b6a-a1ff-9a42c5e07319",
   "metadata": {},
   "source": [
    "### Query 2\n",
    "#### Q: What is the most popular day of the week to take uber?\n",
    "#### A: The most popular day of week to take uber is Wednesday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "c4cb1b92-4dcb-4dd1-b3c5-97a3fec4e3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_2_FILENAME = \"uber_most_popular_day.sql\"\n",
    "QUERY_2 = \"\"\"\n",
    "SELECT\n",
    "    STRFTIME('%w', pickup_datetime) AS day_of_week,\n",
    "    COUNT(*) AS trip_count\n",
    "FROM\n",
    "    uber_trips\n",
    "GROUP BY\n",
    "    day_of_week\n",
    "ORDER BY\n",
    "    trip_count DESC;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "583e320f-735d-4222-9be2-fe0710ca91f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The day starts from 0 to 6 which indicates Sunday to Saturday.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>trip_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>1917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  day_of_week  trip_count\n",
       "0           6        2502\n",
       "1           5        2418\n",
       "2           4        2192\n",
       "3           0        2146\n",
       "4           3        2042\n",
       "5           1        1928\n",
       "6           2        1917"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with engine.connect() as con:\n",
    "    results = con.execute(db.text(QUERY_2)).fetchall()\n",
    "results\n",
    "# or via pandas\n",
    "print(\"The day starts from 0 to 6 which indicates Sunday to Saturday.\")\n",
    "pd.read_sql(QUERY_2, con=engine)\n",
    "\n",
    "# The day starts from 0 to 6 which indicates Sunday to Saturday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "df1812e7-3984-4375-9a3e-203db15bfa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_2, f\"{QUERY_DIRECTORY}/{QUERY_2_FILENAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acac72c-bbf1-43c1-a22f-773dc4431c96",
   "metadata": {},
   "source": [
    "### Query 3\n",
    "#### Q: What’s the 95% percentile of trip distance in January 2024?\r\n",
    "#### A:The 95% percentile of trip distance in January 2024 is 11.72."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "d0395dcd-fd12-476a-9388-68ffb3cf6f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_3_FILENAME = \"trip_distance_Jan2024.sql\"\n",
    "QUERY_3 = \"\"\"\n",
    "WITH rides_data AS (\n",
    "    SELECT trip_distance\n",
    "    FROM taxi_trips\n",
    "    WHERE pickup_time BETWEEN '2024-01-01' AND '2024-01-31'\n",
    "    UNION ALL\n",
    "    SELECT trip_miles AS trip_distance\n",
    "    FROM uber_trips\n",
    "    WHERE pickup_datetime BETWEEN '2024-01-01' AND '2024-01-31'\n",
    "),\n",
    "ordered_distances AS (\n",
    "    SELECT trip_distance\n",
    "    FROM rides_data\n",
    "    ORDER BY trip_distance\n",
    "),\n",
    "percentile AS (\n",
    "    SELECT CAST((COUNT(*) - 1) * 0.95 AS INTEGER) AS position\n",
    "    FROM ordered_distances\n",
    ")\n",
    "SELECT trip_distance AS p95_trip_distance\n",
    "FROM ordered_distances\n",
    "LIMIT 1\n",
    "OFFSET (SELECT position FROM percentile);\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "a238a513-144c-482d-b60c-c33c5252ee23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.53\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as con:\n",
    "    results = con.execute(db.text(QUERY_3)).fetchall()\n",
    "q3_result = results[0][0]  \n",
    "print(q3_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "aad35ae2-692f-40b7-b0eb-32817210f663",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_3, f\"{QUERY_DIRECTORY}/{QUERY_3_FILENAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194ec96c-ab6b-4113-8adb-35c0d81e3ea2",
   "metadata": {},
   "source": [
    "### Query 4: What was the weather like for the busiest days in 2023?\r\n",
    "What were the top 10 days with the highest number of all hired rides for 2023, and for each day, what was the average distance, average precipitation amount, and average wind speed.\r\n",
    "\r\n",
    "The result should be a list of 10 tuples (or a dataframe of 10 rows). Each tuple/row should have five items/columns: a date, an integer for the number of rides, a float for the average distance traveled, a float for the average precipitation amount, and a float the average wind speed. The list of tuples or dataframe should be sorted by total number of rides, descending.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1415885-f9f7-46b5-808e-75896907b34a",
   "metadata": {},
   "source": [
    "1. We join uber and taxi data together as all_rides_2023\n",
    "2. Count total rides of that and group by date name it daily_ride\n",
    "3. Calculate each days avg distance of taxi and uber and union them name it daily_avg_distance\n",
    "4. Then we join the daily ride count per day, with avg distance per day name it busiest_days\n",
    "5. Then we select buiest days and joint with daily weather then sort it and take the top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "e56b908b-cb19-4663-b6a9-63dd7d996904",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_4_FILENAME = \"busiest_days_2023.sql\"\n",
    "QUERY_4 = \"\"\"\n",
    "WITH all_rides_2023 AS (\n",
    "    SELECT DATE(pickup_time) AS ride_date\n",
    "    FROM taxi_trips\n",
    "    WHERE pickup_time BETWEEN '2023-01-01' AND '2023-12-31'\n",
    "    UNION ALL\n",
    "    SELECT DATE(pickup_datetime) AS ride_date\n",
    "    FROM uber_trips\n",
    "    WHERE pickup_datetime BETWEEN '2023-01-01' AND '2023-12-31'\n",
    "),\n",
    "daily_ride_counts AS (\n",
    "    SELECT \n",
    "        ride_date,\n",
    "        COUNT(*) AS total_rides\n",
    "    FROM all_rides_2023\n",
    "    GROUP BY ride_date\n",
    "),\n",
    "daily_avg_distance AS (\n",
    "    SELECT \n",
    "        DATE(pickup_time) AS ride_date,\n",
    "        AVG(trip_distance) AS avg_distance\n",
    "    FROM taxi_trips\n",
    "    WHERE pickup_time BETWEEN '2023-01-01' AND '2023-12-31'\n",
    "    GROUP BY DATE(pickup_time)\n",
    "    UNION ALL\n",
    "    SELECT \n",
    "        DATE(pickup_datetime) AS ride_date,\n",
    "        AVG(trip_miles) AS avg_distance\n",
    "    FROM uber_trips\n",
    "    WHERE pickup_datetime BETWEEN '2023-01-01' AND '2023-12-31'\n",
    "    GROUP BY DATE(pickup_datetime)\n",
    "),\n",
    "busiest_days AS (\n",
    "    SELECT \n",
    "        daily_ride_counts.ride_date,\n",
    "        daily_ride_counts.total_rides,\n",
    "        grouped_avg_distance.avg_distance\n",
    "    FROM daily_ride_counts\n",
    "    JOIN (\n",
    "        SELECT daily_avg_distance.ride_date, AVG(daily_avg_distance.avg_distance) AS avg_distance\n",
    "        FROM daily_avg_distance\n",
    "        GROUP BY daily_avg_distance.ride_date\n",
    "    ) grouped_avg_distance\n",
    "    ON daily_ride_counts.ride_date = grouped_avg_distance.ride_date\n",
    "    ORDER BY daily_ride_counts.total_rides DESC\n",
    "    LIMIT 10\n",
    ")\n",
    "SELECT \n",
    "    busiest_days.ride_date,\n",
    "    busiest_days.total_rides,\n",
    "    busiest_days.avg_distance,\n",
    "    daily_weather.average_precipitation,\n",
    "    daily_weather.average_wind_speed\n",
    "FROM busiest_days\n",
    "LEFT JOIN daily_weather\n",
    "ON busiest_days.ride_date = daily_weather.date\n",
    "ORDER BY busiest_days.total_rides DESC;\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "071705f0-3e74-4a1b-b1e8-5073a88b28c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2023-06-10', 35, 4.126176470588235, 0.0, 3.9565217391304346), ('2023-07-11', 35, 4.421333333333333, 0.0, 2.9545454545454546), ('2023-04-28', 34, 4.0608571428571425, 0.018214285714285714, 6.051282051282051), ('2023-06-14', 34, 3.688535714285714, 0.017037037037037038, 4.0), ('2023-09-13', 34, 4.065227272727273, 0.014642857142857143, 2.6285714285714286), ('2023-10-15', 33, 3.6063690476190473, 0.0004347826086956522, 5.56), ('2023-06-13', 32, 4.600238095238096, 0.0, 5.208333333333333), ('2023-07-13', 32, 4.33538961038961, 0.0, 2.3333333333333335), ('2023-02-25', 31, 4.386469298245614, 0.0, 3.2962962962962963), ('2023-04-19', 31, 2.2508152173913043, 0.0, 5.875)]\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as con:\n",
    "    results = con.execute(db.text(QUERY_4)).fetchall()\n",
    "q4_result = results\n",
    "print(q4_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "97579cae-2ca2-440d-b07f-9b80fce0dc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_4, f\"{QUERY_DIRECTORY}/{QUERY_4_FILENAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203db157-a2d5-411e-91ba-18273d669fe6",
   "metadata": {},
   "source": [
    "### Query 5: How many rides were hired during snow days?\n",
    "Which 10 days in between January 2020 and August 2024 (inclusive) had the most snow, and how many hired trips were made on those days?\n",
    "\n",
    "The result should be a list of 10 tuples. Each tuple should have three items: a date, a float for the total snowfall of that day, and the number of hired trips for that day. The list of tuples should be sorted by snowfall, descending.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbdbc4f-7216-48c9-ba6b-3c9421807133",
   "metadata": {},
   "source": [
    "1. We join Uber and Taxi data together as all_rides.\n",
    "2. Count total rides of that and group by date, name it daily_ride_counts.\n",
    "3. Filter days with snowfall from daily_weather, name it snow_days.\n",
    "4. Sort snowfall data and take the top 10 snowiest days, name it snowiest_days.\n",
    "5. Join snowiest_days with daily_ride_counts, then sort and output the top 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "ac19c192-5b0b-45fa-a53f-8faf193ba253",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_5_FILENAME = \"rides_hired_snowdays.sql\"\n",
    "QUERY_5 = \"\"\"\n",
    "WITH all_rides AS (\n",
    "    SELECT DATE(pickup_time) AS ride_date\n",
    "    FROM taxi_trips\n",
    "    WHERE pickup_time BETWEEN '2020-01-01' AND '2024-08-31'\n",
    "    UNION ALL\n",
    "    SELECT DATE(pickup_datetime) AS ride_date\n",
    "    FROM uber_trips\n",
    "    WHERE pickup_datetime BETWEEN '2020-01-01' AND '2024-08-31'\n",
    "),\n",
    "daily_ride_counts AS (\n",
    "    SELECT \n",
    "        ride_date,\n",
    "        COUNT(*) AS total_rides\n",
    "    FROM all_rides\n",
    "    GROUP BY ride_date\n",
    "),\n",
    "snow_days AS (\n",
    "    SELECT \n",
    "        date AS snow_date,\n",
    "        total_snowfall\n",
    "    FROM daily_weather\n",
    "    WHERE total_snowfall > 0 AND date BETWEEN '2020-01-01' AND '2024-08-31'\n",
    "),\n",
    "snowiest_days AS (\n",
    "    SELECT \n",
    "        snow_date,\n",
    "        total_snowfall\n",
    "    FROM snow_days\n",
    "    ORDER BY total_snowfall DESC\n",
    "    LIMIT 10\n",
    ")\n",
    "SELECT \n",
    "    snowiest_days.snow_date,\n",
    "    snowiest_days.total_snowfall,\n",
    "    COALESCE(daily_ride_counts.total_rides, 0) AS total_rides\n",
    "FROM snowiest_days\n",
    "LEFT JOIN daily_ride_counts\n",
    "ON snowiest_days.snow_date = daily_ride_counts.ride_date\n",
    "ORDER BY snowiest_days.total_snowfall DESC;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "dd9be801-4a03-4196-9d2c-4c6610496d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2021-02-01', 14.8, 3), ('2022-01-29', 7.3, 21), ('2020-12-16', 6.5, 20), ('2022-01-07', 5.8, 21), ('2021-02-07', 4.5, 15), ('2020-12-17', 4.0, 11), ('2021-02-18', 3.2, 18), ('2024-02-13', 3.2, 18), ('2020-01-18', 2.1, 22), ('2021-01-31', 2.0, 15)]\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as con:\n",
    "    results = con.execute(db.text(QUERY_5)).fetchall()\n",
    "q5_result = results\n",
    "print(q5_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "0bf7c3a5-a829-4beb-83a6-12989fb8c196",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_5, f\"{QUERY_DIRECTORY}/{QUERY_5_FILENAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17635af-cfb3-45e2-a675-85e5eed922b3",
   "metadata": {},
   "source": [
    "### Query 6\n",
    "Tropical Storm Ophelia (September 28-30, 2023) set a new daily rainfall record in NYC with 8.05 inches of rain measured, causing flooding across all of the city. During Ophelia, plus 3 days leading up to it and 3 days after it, how many trips were taken each hour, and for each hour, how much precipitation did NYC receive, and what was the sustained wind speed?\n",
    "\n",
    "The result should be a list of roughly 216 tuples/rows (24 hours/day, 9 days), where each tuple is an entry for every single hour of the given date range, even if no rides were taken, no precipitation was measured, or there was no wind. Each tuple should have four items: a string for the date and hour, an int for the number of hired rides in that hour, the float for the total precipitation for that hour, and a float for the average wind speed for that hour. The list of tuples should be ordered by date+hour, ascending.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf6ae97-89c3-4017-b28e-c7ea75ebacb7",
   "metadata": {},
   "source": [
    "1. We select all rides each hour by union taxi and uber group by hours between given time zone name it all_rides\n",
    "2. Use all_rides we count each hours total hired rides\n",
    "3. Select all weathers from weather_hour between given time zone add a column for ride counts and set all values to 0\n",
    "4. Join weather per hour with hourly counted rides sum their hourly counted rides, if hourly_ride_counts.total_rides is missed, sum a 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "afca0dcc-d3c3-49b6-b0c1-fe846fabb29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_6_FILENAME = \"Tropical_storm_ophelia.sql\"\n",
    "QUERY_6 = \"\"\"\n",
    "WITH all_rides AS (\n",
    "    SELECT strftime('%Y-%m-%d %H:00:00', pickup_time) AS ride_hour\n",
    "    FROM taxi_trips\n",
    "    WHERE pickup_time BETWEEN '2023-09-25 00:00:00' AND '2023-10-03 23:59:59'\n",
    "    UNION ALL\n",
    "    SELECT strftime('%Y-%m-%d %H:00:00', pickup_datetime) AS ride_hour\n",
    "    FROM uber_trips\n",
    "    WHERE pickup_datetime BETWEEN '2023-09-25 00:00:00' AND '2023-10-03 23:59:59'\n",
    "),\n",
    "hourly_ride_counts AS (\n",
    "    SELECT \n",
    "        ride_hour,\n",
    "        COUNT(*) AS total_rides\n",
    "    FROM all_rides\n",
    "    GROUP BY ride_hour\n",
    "),\n",
    "hourly_weather_with_rides AS (\n",
    "    SELECT \n",
    "        strftime('%Y-%m-%d %H:00:00', date) AS weather_hour,\n",
    "        SUM(hourlyprecipitation) AS total_precipitation,\n",
    "        AVG(hourlywindspeed) AS avg_wind_speed,\n",
    "        0 AS hourly_ride_counts\n",
    "    FROM hourly_weather\n",
    "    WHERE date BETWEEN '2023-09-25 00:00:00' AND '2023-10-03 23:59:59'\n",
    "    GROUP BY weather_hour\n",
    ")\n",
    "SELECT \n",
    "    hourly_weather_with_rides.weather_hour,\n",
    "    (hourly_weather_with_rides.hourly_ride_counts + COALESCE(hourly_ride_counts.total_rides, 0)) AS total_rides,\n",
    "    hourly_weather_with_rides.total_precipitation,\n",
    "    hourly_weather_with_rides.avg_wind_speed\n",
    "FROM hourly_weather_with_rides\n",
    "LEFT JOIN hourly_ride_counts\n",
    "ON hourly_weather_with_rides.weather_hour = hourly_ride_counts.ride_hour\n",
    "ORDER BY hourly_weather_with_rides.weather_hour ASC;\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "65465d74-90d9-4990-b52c-44de0de3beb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2023-09-25 00:00:00', 0, 0.07, 8.333333333333334), ('2023-09-25 01:00:00', 0, 0.12, 7.0), ('2023-09-25 02:00:00', 0, 0.14, 7.0), ('2023-09-25 03:00:00', 0, 0.04, 7.0), ('2023-09-25 04:00:00', 1, 0.01, 6.0), ('2023-09-25 05:00:00', 0, 0.17, 8.5), ('2023-09-25 06:00:00', 0, 0.07, 7.666666666666667), ('2023-09-25 07:00:00', 0, 0.07, 6.75), ('2023-09-25 08:00:00', 1, 0.07, 10.0), ('2023-09-25 09:00:00', 1, 0.02, 10.0), ('2023-09-25 10:00:00', 2, 0.03, 10.333333333333334), ('2023-09-25 11:00:00', 2, 0.03, 12.333333333333334), ('2023-09-25 12:00:00', 2, 0.02, 9.0), ('2023-09-25 13:00:00', 0, 0.01, 10.0), ('2023-09-25 14:00:00', 1, 0.01, 8.0), ('2023-09-25 15:00:00', 1, 0.09, 10.6), ('2023-09-25 16:00:00', 0, 0.03, 15.0), ('2023-09-25 17:00:00', 1, None, 9.5), ('2023-09-25 18:00:00', 1, None, 9.5), ('2023-09-25 19:00:00', 3, 0.0, 15.0), ('2023-09-25 20:00:00', 3, 0.0, 11.0), ('2023-09-25 21:00:00', 1, 0.0, 11.0), ('2023-09-25 22:00:00', 0, 0.0, 10.0), ('2023-09-25 23:00:00', 0, None, 8.0), ('2023-09-26 00:00:00', 0, 0.02, 8.0), ('2023-09-26 01:00:00', 0, 0.02, 6.0), ('2023-09-26 02:00:00', 0, 0.0, 10.666666666666666), ('2023-09-26 03:00:00', 0, 0.0, 10.0), ('2023-09-26 04:00:00', 0, None, 9.0), ('2023-09-26 05:00:00', 1, None, 8.0), ('2023-09-26 06:00:00', 0, None, 6.0), ('2023-09-26 07:00:00', 1, 0.01, 9.0), ('2023-09-26 08:00:00', 2, 0.06, 7.6), ('2023-09-26 09:00:00', 0, 0.03, 9.0), ('2023-09-26 10:00:00', 0, 0.05, 7.333333333333333), ('2023-09-26 11:00:00', 2, 0.03, 6.666666666666667), ('2023-09-26 12:00:00', 0, 0.03, 6.0), ('2023-09-26 13:00:00', 1, 0.02, 7.0), ('2023-09-26 14:00:00', 2, 0.03, 4.666666666666667), ('2023-09-26 15:00:00', 1, 0.01, 3.5), ('2023-09-26 16:00:00', 2, None, 4.25), ('2023-09-26 17:00:00', 1, 0.0, 0.0), ('2023-09-26 18:00:00', 2, 0.0, 5.0), ('2023-09-26 19:00:00', 0, 0.0, 5.0), ('2023-09-26 20:00:00', 0, 0.0, 6.0), ('2023-09-26 21:00:00', 3, 0.0, 5.0), ('2023-09-26 22:00:00', 0, 0.0, 8.0), ('2023-09-26 23:00:00', 1, 0.0, 7.0), ('2023-09-27 00:00:00', 0, 0.0, 9.0), ('2023-09-27 01:00:00', 0, 0.0, 7.0), ('2023-09-27 02:00:00', 0, 0.0, 7.0), ('2023-09-27 03:00:00', 0, 0.0, 3.0), ('2023-09-27 04:00:00', 0, 0.0, 3.0), ('2023-09-27 05:00:00', 0, 0.0, 6.0), ('2023-09-27 06:00:00', 1, 0.0, 6.0), ('2023-09-27 07:00:00', 3, 0.0, 7.0), ('2023-09-27 08:00:00', 1, 0.0, 15.0), ('2023-09-27 09:00:00', 0, 0.0, 14.0), ('2023-09-27 10:00:00', 2, 0.0, 8.0), ('2023-09-27 11:00:00', 2, 0.0, 10.0), ('2023-09-27 12:00:00', 1, 0.0, 8.0), ('2023-09-27 13:00:00', 2, 0.0, 10.0), ('2023-09-27 14:00:00', 1, 0.0, 6.0), ('2023-09-27 15:00:00', 1, 0.0, 6.0), ('2023-09-27 16:00:00', 1, 0.0, 7.0), ('2023-09-27 17:00:00', 2, 0.0, 5.0), ('2023-09-27 18:00:00', 0, 0.0, 5.0), ('2023-09-27 19:00:00', 3, 0.0, 5.0), ('2023-09-27 20:00:00', 0, 0.0, 5.0), ('2023-09-27 21:00:00', 2, 0.0, 3.0), ('2023-09-27 22:00:00', 2, 0.0, 5.0), ('2023-09-27 23:00:00', 1, 0.0, 6.0), ('2023-09-28 00:00:00', 0, 0.0, 6.0), ('2023-09-28 01:00:00', 0, 0.0, 8.0), ('2023-09-28 02:00:00', 0, 0.0, 6.5), ('2023-09-28 03:00:00', 0, 0.0, 5.5), ('2023-09-28 04:00:00', 0, 0.0, 7.0), ('2023-09-28 05:00:00', 1, 0.0, 7.0), ('2023-09-28 06:00:00', 1, 0.0, 7.0), ('2023-09-28 07:00:00', 0, 0.0, 5.0), ('2023-09-28 08:00:00', 1, 0.0, 10.0), ('2023-09-28 09:00:00', 0, 0.0, 7.0), ('2023-09-28 10:00:00', 1, 0.0, 8.0), ('2023-09-28 11:00:00', 3, None, 9.0), ('2023-09-28 12:00:00', 1, None, 10.0), ('2023-09-28 13:00:00', 1, 0.0, 8.0), ('2023-09-28 14:00:00', 2, 0.0, 7.0), ('2023-09-28 15:00:00', 1, None, 11.0), ('2023-09-28 16:00:00', 2, 0.14, 7.5), ('2023-09-28 17:00:00', 0, 0.01, 0.0), ('2023-09-28 18:00:00', 1, 0.0, 5.0), ('2023-09-28 19:00:00', 2, 0.0, 0.0), ('2023-09-28 20:00:00', 0, 0.03, 3.0), ('2023-09-28 21:00:00', 1, 0.07, 5.0), ('2023-09-28 22:00:00', 3, 0.45, 7.0), ('2023-09-28 23:00:00', 4, 0.5, 6.5), ('2023-09-29 00:00:00', 2, 0.32, 6.666666666666667), ('2023-09-29 01:00:00', 0, 0.11, 8.0), ('2023-09-29 02:00:00', 0, 0.72, 8.25), ('2023-09-29 03:00:00', 0, 0.19, 7.75), ('2023-09-29 04:00:00', 1, 0.13, 8.5), ('2023-09-29 05:00:00', 0, 0.32, 7.666666666666667), ('2023-09-29 06:00:00', 0, 0.54, 5.0), ('2023-09-29 07:00:00', 2, 1.62, 6.0), ('2023-09-29 08:00:00', 0, 3.71, 6.333333333333333), ('2023-09-29 09:00:00', 0, 2.09, 10.5), ('2023-09-29 10:00:00', 4, 0.38, 9.5), ('2023-09-29 11:00:00', 1, 0.2, 10.0), ('2023-09-29 12:00:00', 0, 0.67, 9.5), ('2023-09-29 13:00:00', 0, 0.07, 11.0), ('2023-09-29 14:00:00', 1, 0.02, 9.0), ('2023-09-29 15:00:00', 1, None, 7.0), ('2023-09-29 16:00:00', 3, None, 9.0), ('2023-09-29 17:00:00', 2, 0.01, 6.0), ('2023-09-29 18:00:00', 1, None, 3.0), ('2023-09-29 19:00:00', 1, 0.0, 7.0), ('2023-09-29 20:00:00', 2, 0.0, 7.0), ('2023-09-29 21:00:00', 2, 0.0, 8.0), ('2023-09-29 22:00:00', 1, 0.0, 8.0), ('2023-09-29 23:00:00', 0, 0.0, 8.0), ('2023-09-30 00:00:00', 0, 0.0, 9.0), ('2023-09-30 01:00:00', 0, 0.0, 7.0), ('2023-09-30 02:00:00', 0, 0.0, 6.5), ('2023-09-30 03:00:00', 0, 0.0, 5.0), ('2023-09-30 04:00:00', 1, None, 6.0), ('2023-09-30 05:00:00', 0, None, 6.0), ('2023-09-30 06:00:00', 1, None, 6.0), ('2023-09-30 07:00:00', 1, 0.03, 6.6), ('2023-09-30 08:00:00', 2, 0.01, 6.0), ('2023-09-30 09:00:00', 1, None, 7.0), ('2023-09-30 10:00:00', 0, 0.03, 7.0), ('2023-09-30 11:00:00', 0, 0.0, 5.333333333333333), ('2023-09-30 12:00:00', 4, 0.0, 6.5), ('2023-09-30 13:00:00', 1, 0.0, 7.0), ('2023-09-30 14:00:00', 1, 0.0, 7.0), ('2023-09-30 15:00:00', 2, 0.0, 6.0), ('2023-09-30 16:00:00', 0, 0.0, 2.6666666666666665), ('2023-09-30 17:00:00', 1, 0.0, 4.5), ('2023-09-30 18:00:00', 5, 0.0, 5.0), ('2023-09-30 19:00:00', 0, 0.0, 0.0), ('2023-09-30 20:00:00', 1, 0.0, 5.0), ('2023-09-30 21:00:00', 3, 0.0, 3.0), ('2023-09-30 22:00:00', 0, 0.0, 0.0), ('2023-09-30 23:00:00', 1, 0.0, 5.0), ('2023-10-01 00:00:00', 1, 0.0, 0.0), ('2023-10-01 02:00:00', 0, 0.0, 3.0), ('2023-10-01 03:00:00', 0, 0.0, 3.0), ('2023-10-01 04:00:00', 0, 0.0, 3.0), ('2023-10-01 05:00:00', 0, 0.0, 0.0), ('2023-10-01 06:00:00', 0, 0.0, 5.0), ('2023-10-01 07:00:00', 0, 0.0, 3.0), ('2023-10-01 08:00:00', 0, 0.0, 7.0), ('2023-10-01 09:00:00', 1, 0.0, 6.0), ('2023-10-01 10:00:00', 3, 0.0, 6.0), ('2023-10-01 11:00:00', 1, 0.0, 8.0), ('2023-10-01 12:00:00', 1, 0.0, 6.0), ('2023-10-01 13:00:00', 2, 0.0, 5.0), ('2023-10-01 14:00:00', 1, 0.0, 9.0), ('2023-10-01 15:00:00', 0, 0.0, 8.0), ('2023-10-01 16:00:00', 2, 0.0, 5.0), ('2023-10-01 17:00:00', 1, 0.0, 3.0), ('2023-10-01 18:00:00', 1, 0.0, 3.0), ('2023-10-01 19:00:00', 1, 0.0, 6.0), ('2023-10-01 20:00:00', 0, 0.0, 3.0), ('2023-10-01 21:00:00', 0, 0.0, 0.0), ('2023-10-01 22:00:00', 0, 0.0, 3.0), ('2023-10-01 23:00:00', 0, 0.0, 3.0), ('2023-10-02 00:00:00', 1, 0.0, 3.0), ('2023-10-02 01:00:00', 0, 0.0, 3.0), ('2023-10-02 02:00:00', 0, 0.0, 0.0), ('2023-10-02 03:00:00', 0, 0.0, 3.0), ('2023-10-02 04:00:00', 0, 0.0, 0.0), ('2023-10-02 05:00:00', 0, 0.0, 3.0), ('2023-10-02 06:00:00', 0, 0.0, 0.0), ('2023-10-02 07:00:00', 1, 0.0, 0.0), ('2023-10-02 08:00:00', 0, 0.0, 6.0), ('2023-10-02 09:00:00', 1, 0.0, 0.0), ('2023-10-02 10:00:00', 1, 0.0, 5.0), ('2023-10-02 11:00:00', 1, 0.0, 7.0), ('2023-10-02 12:00:00', 2, 0.0, 0.0), ('2023-10-02 13:00:00', 0, 0.0, 5.0), ('2023-10-02 14:00:00', 0, 0.0, 6.0), ('2023-10-02 15:00:00', 1, 0.0, 7.0), ('2023-10-02 16:00:00', 3, 0.0, 7.0), ('2023-10-02 17:00:00', 1, 0.0, 0.0), ('2023-10-02 18:00:00', 0, 0.0, 0.0), ('2023-10-02 19:00:00', 4, 0.0, 0.0), ('2023-10-02 20:00:00', 2, 0.0, 0.0), ('2023-10-02 21:00:00', 0, 0.0, 0.0), ('2023-10-02 22:00:00', 1, 0.0, 0.0), ('2023-10-02 23:00:00', 0, 0.0, 0.0), ('2023-10-03 00:00:00', 0, 0.0, 0.0), ('2023-10-03 01:00:00', 0, 0.0, 0.0), ('2023-10-03 02:00:00', 0, 0.0, 0.0), ('2023-10-03 03:00:00', 0, 0.0, 0.0), ('2023-10-03 04:00:00', 0, 0.0, 0.0), ('2023-10-03 05:00:00', 0, 0.0, 0.0), ('2023-10-03 06:00:00', 1, 0.0, 0.0), ('2023-10-03 07:00:00', 1, 0.0, 3.0), ('2023-10-03 08:00:00', 2, 0.0, 3.0), ('2023-10-03 09:00:00', 2, 0.0, 0.0), ('2023-10-03 10:00:00', 3, 0.0, 3.0), ('2023-10-03 11:00:00', 0, 0.0, 6.0), ('2023-10-03 12:00:00', 1, 0.0, 0.0), ('2023-10-03 13:00:00', 2, 0.0, 3.0), ('2023-10-03 14:00:00', 0, 0.0, 0.0), ('2023-10-03 15:00:00', 0, 0.0, 0.0), ('2023-10-03 16:00:00', 0, 0.0, 0.0), ('2023-10-03 17:00:00', 0, 0.0, 0.0), ('2023-10-03 18:00:00', 0, 0.0, 0.0), ('2023-10-03 19:00:00', 2, 0.0, 0.0), ('2023-10-03 20:00:00', 1, 0.0, 0.0), ('2023-10-03 21:00:00', 0, 0.0, 0.0), ('2023-10-03 22:00:00', 0, 0.0, 0.0), ('2023-10-03 23:00:00', 1, 0.0, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as con:\n",
    "    results = con.execute(db.text(QUERY_6)).fetchall()\n",
    "q6_result = results\n",
    "print(q6_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "ebd0420f-29af-4edd-a0fd-b2776ca32b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_6, f\"{QUERY_DIRECTORY}/{QUERY_6_FILENAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ced42",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9eef42",
   "metadata": {},
   "source": [
    "### Visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_1(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ced2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_1():\n",
    "    # Query SQL database for the data needed.\n",
    "    # You can put the data queried into a pandas dataframe, if you wish\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_1()\n",
    "plot_visual_1(some_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
